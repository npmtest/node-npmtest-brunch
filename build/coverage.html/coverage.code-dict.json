{"/home/travis/build/npmtest/node-npmtest-brunch/test.js":"/* istanbul instrument in package npmtest_brunch */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-brunch/lib.npmtest_brunch.js":"/* istanbul instrument in package npmtest_brunch */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_brunch = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_brunch = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-brunch/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-brunch && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_brunch */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_brunch\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_brunch.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_brunch.rollup.js'] =\n            local.assetsDict['/assets.npmtest_brunch.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_brunch.__dirname + '/lib.npmtest_brunch.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/index.js":"'use strict';\nrequire('micro-es7-shim');\nrequire('promise.prototype.finally').shim();\nconst logger = require('loggy');\nconst BrunchError = require('./utils/error');\nconst checkLegacyNewSyntax = options => {\n  const rawArgs = options.parent.rawArgs;\n  const newArgs = rawArgs.slice(rawArgs.indexOf('new') + 1);\n  const oldSyntax = !options.skeleton && newArgs.length === 2;\n  if (!oldSyntax) return;\n\n  throw new BrunchError('LEGACY_NEW_SYNTAX', {\n    skeleton: newArgs[0],\n    path: newArgs[1],\n  });\n};\n\nconst hasDebug = obj => {\n  return obj && typeof obj === 'object' && obj.debug;\n};\n\nconst defaultSkeleton = 'https://github.com/brunch/dead-simple';\nexports.new = (rootPath, options) => {\n  checkLegacyNewSyntax(options);\n\n  const initSkeleton = require('init-skeleton').init;\n  const skeleton = options.skeleton ||\n    process.env.BRUNCH_INIT_SKELETON ||\n    defaultSkeleton;\n\n  return initSkeleton(skeleton, {\n    logger,\n    rootPath,\n    commandName: 'brunch new',\n  });\n};\n\nconst start = (persistent, arg2, arg3) => {\n  const isDebug = hasDebug(arg2) || hasDebug(arg3);\n  if (isDebug) {\n    let ns = typeof isDebug === 'string' ? isDebug : '*';\n    if (ns !== 'speed') ns = `brunch:${ns}`;\n    process.env.DEBUG = ns;\n  }\n  // We require `watch` after we assigned `process.env.DEBUG` any value.\n  // Otherwise it would be `undefined` and debug messages wouldn't be shown.\n  return require('./watch')(persistent, arg2, arg3);\n};\n\nexports.build = start.bind(null, false);\nexports.watch = start.bind(null, true);\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/error.js":"'use strict';\nconst messages = require('./messages');\nconst format = (template, params) => {\n  let withError = false;\n  let message = template.replace(/#{\\s*(\\w+)\\s*}/g, (_, key) => {\n    if (key === 'error') withError = true;\n    return params[key] || '';\n  });\n\n  if (!withError) message += `\\n${params.error || ''}`;\n  return message;\n};\n\nclass BrunchError extends Error {\n  constructor(code, params) {\n    const message = format(messages[code] || code, params || {});\n    super(message);\n\n    this.name = 'BrunchError';\n    this.code = code;\n  }\n}\n\nmodule.exports = BrunchError;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/cli.js":"'use strict';\n\n/* eslint-disable prefer-arrow-callback, prefer-template */\n/* eslint-env es6:false */\nvar version = process.versions.node;\nif (parseInt(version) < 4) {\n  console.error(\n    'Your global Brunch installation is trying to load local Brunch v2+, ' +\n    'which only supports Node.js v4 or higher (you have ' + version + ').\\n' +\n    'You have two choices:\\n' +\n    '  a) Update Node.js to v4+. Then update global Brunch: ' +\n    '`npm un -g brunch && npm i -g brunch`\\n' +\n    '  b) Adjust package.json to use Brunch 1.x (outdated, not recommended).'\n  );\n  process.exit(1);\n}\n\n// The files use ES2015, which cannot be used with old Brunches.\nvar program = require('commander');\nvar logger = require('loggy');\nvar commands = require('.');\n\nprogram\n  .version(require('../package.json').version, '-v, --version')\n  .usage('[command] [options]');\n\nprogram.command('new [path]')\n  .alias('n')\n  .description('Create new Brunch project in path.')\n  .option('-s, --skeleton [name]', 'skeleton name or URL from brunch.io/skeletons')\n  .on('--help', function() {\n    require('init-skeleton').printBanner('brunch new -s');\n  })\n  .action(commands.new);\n\nprogram.command('build [path]')\n  .alias('b')\n  .description('Build a Brunch project.')\n  .option('-e, --env [setting]', 'specify a set of override settings to apply')\n  .option('-p, --production', 'same as `--env production`')\n  .option('-d, --debug [pattern]', 'print verbose debug output to stdout')\n  .option('-j, --jobs [num]', 'parallelize the build')\n  .option('-c, --config [path]', 'specify a path to Brunch config file')\n  .action(commands.build);\n\nprogram.command('watch [path]')\n  .alias('w')\n  .description('Watch Brunch directory and rebuild if something changed.')\n  .option('-e, --env [setting]', 'specify a set of override settings to apply')\n  .option('-p, --production', 'same as `--env production`')\n  .option('-s, --server', 'run a simple http server for the public dir on localhost')\n  .option('-n, --network', 'if `server` was given, allow access from the network')\n  .option('-P, --port [port]', 'if `server` was given, listen on this port')\n  .option('-d, --debug [pattern]', 'print verbose debug output to stdout')\n  .option('-j, --jobs [num]', 'parallelize the build')\n  .option('-c, --config [path]', 'specify a path to Brunch config file')\n  .option('--stdin', 'listen to stdin and exit when stdin closes')\n  .action(commands.watch);\n\nvar checkForRemovedOptions = function(args, command) {\n  var hasArg = function(deprs) {\n    return deprs.some(function(arg) {\n      return args.includes(arg);\n    });\n  };\n  var hasCommand = function(valid) {\n    return valid.includes(command);\n  };\n  // Deprecations\n  if (hasArg(['-o', '--optimize'])) {\n    return '--optimize has been removed. Use `-p / --production`';\n  }\n  if (hasCommand(['g', 'd', 'generate', 'destroy'])) {\n    return '`brunch generate / destroy` command has been removed.\\n\\nUse scaffolt (https://github.com/paulmillr/scaffolt)\\nsuccessor or similar:\\n    npm install -g scaffolt\\n    scaffolt <type> <name> [options]\\n    scaffolt <type> <name> [options] --revert';\n  }\n  if (hasCommand(['t', 'test'])) {\n    return '`brunch test` command has been removed.\\n\\nUse mocha-phantomjs (http://metaskills.net/mocha-phantomjs/)\\nsuccessor or similar:\\n    npm install -g mocha-phantomjs\\n    mocha-phantomjs [options] <your-html-file-or-url>';\n  }\n  var pIndex = args.indexOf('-p');\n  if (pIndex !== -1) {\n    // if -p is followed by a number, the user probably wants to specify the port\n    // the new option name for port is -P\n    var port = +args[pIndex + 1];\n    if (Number.isInteger(port)) {\n      var parsed = args.slice(2).map(function(arg) {\n        return arg === '-p' ? '-P' : arg;\n      });\n      var corrected = ['brunch'].concat(parsed).join(' ');\n      return 'The `-p` option is no longer used to specify the port. Use `-P` instead, e.g. `' + corrected + '`';\n    }\n  }\n};\n\n// The fn would be executed every time user run `bin/brunch`.\nexports.run = function() {\n  var args = process.argv.slice();\n  var command = args[2];\n\n  // Need this since `brunch` binary will fork and run `run-cli`,\n  // but we still want to see `brunch` in help.\n  args[1] = 'brunch';\n\n  var error = checkForRemovedOptions(args, command);\n  if (error) {\n    logger.error(error);\n    return;\n  }\n\n  program.parse(args);\n\n  var validCommand = program.commands.some(function(cmd) {\n    return cmd.name() === command || cmd.alias() === command;\n  });\n\n  if (!validCommand) program.help();\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/run-cli.js":"'use strict';\n// For workers.\nrequire('./cli').run();\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/watch.js":"'use strict';\nconst sysPath = require('universal-path');\nconst getRelativePath = sysPath.relative;\nconst logger = require('loggy');\nconst chokidar = require('chokidar');\nconst debug = require('debug')('brunch:watch');\nconst speed = require('since-app-start');\nconst serveBrunch = require('serve-brunch');\nconst cpus = require('os').cpus().length;\nconst deppack = require('deppack');\nconst install = require('deps-install');\n\nconst workers = require('./workers'); // close, init\nconst write = require('./fs_utils/write');\nconst ignored = require('./fs_utils/is_ignored');\nconst FileList = require('./fs_utils/file_list');\nconst pipeline = require('./fs_utils/pipeline');\n\nconst application = require('./utils/config'); // loadConfig, install\nconst plugins = require('./utils/plugins');\nconst helpers = require('./utils/helpers'); // asyncFilter, flatten, generateCompilationLog, getCompilationProgress\n\nconst promisifyHook = plugin => {\n  const hook = plugin.preCompile;\n  if (!hook.length) return;\n  plugin.preCompile = () => new Promise(resolve => {\n    hook.call(plugin, resolve);\n  });\n};\n\nconst mergeHooks = (plugins, config) => {\n  return Object.keys(plugins).reduce((mergedHooks, name) => {\n    const allHooks = plugins[name].concat(config);\n    if (name === 'preCompile') {\n      allHooks.forEach(promisifyHook);\n    }\n\n    mergedHooks[name] = function() {\n      // => has lexical `arguments`\n      return allHooks.map(plugin => {\n        return plugin[name].apply(plugin, arguments);\n      });\n    };\n\n    return mergedHooks;\n  }, {});\n};\n\nconst filterNonExistentPaths = paths => {\n  return Promise.all(paths.map(helpers.fsExists)).then(values => {\n    // watched files\n    return paths.filter((path, index) => values[index]);\n  });\n};\n\n// Filter paths that exist and watch them with `chokidar` package.\nconst getWatchedPaths = config => {\n  const configs = config.paths.allConfigFiles;\n  const pkg = config.packageInfo;\n  const getFiles = pkgs => helpers.flatten(pkgs.components.map(c => c.files));\n  const watched = config.paths.watched.concat(configs, getFiles(pkg.npm), getFiles(pkg.bower));\n  return filterNonExistentPaths(watched);\n};\n\nconst setDefaultJobsCount = jobs => {\n  const MAX_JOBS = 32;\n  const env = process.env.BRUNCH_JOBS;\n  if (!jobs && !env || jobs === true) return;\n  // Mitigates Intel Hyperthreading.\n  const str = jobs || env || cpus / 2;\n  const int = Math.round(str);\n  return isNaN(int) ||\n    int < 1 ||\n    int > MAX_JOBS ? 1 : int;\n};\n\n/* persistent - Boolean: should brunch build the app only once or watch it?\n * options    - Object: {configPath, optimize, server, port}.\n *              Only configPath is required.\n * onCompile  - Function that will be executed after every successful\n *              compilation. May receive an array of `fs_utils.GeneratedFile`.\n *\n * this.config is an application config.\n * this._startTime is a mutable timestamp that represents latest compilation\n * start time. It is `null` when there are no compilations.\n */\nclass BrunchWatcher {\n  constructor(persistent, options, onCompile) {\n    speed.profile('Created BrunchWatcher');\n    this._constructorOptions = arguments;\n    this._startTime = Date.now() - speed.sinceStart;\n    this._isFirstRun = true;\n    this._onReload = options._onReload;\n    options.jobs = setDefaultJobsCount(options.jobs);\n\n    if (!persistent) {\n      process.on('exit', previousCode => {\n        const currentCode = logger.errorHappened ? 1 : previousCode;\n        process.exit(currentCode);\n      });\n    }\n\n    application.loadConfig(persistent, options)\n      .then(cfg => {\n        this.config = cfg;\n        if (options.jobs > 1) {\n          workers.init(options, cfg);\n        }\n        return Promise.all([\n          getWatchedPaths(cfg._normalized),\n          serveBrunch.serve(cfg.server),\n          plugins(cfg, options.dependencies),\n        ]);\n      })\n      .then(res => {\n        const cfg = this.config;\n        const watchedPaths = res[0];\n        this.server = res[1];\n        const hooks = res[2].hooks;\n        hooks.onCompile.push({onCompile});\n        this.hooks = mergeHooks(hooks, cfg.hooks);\n        const plugins = this.plugins = res[2].plugins;\n\n        pipeline.setPlugins(plugins.all);\n        pipeline.setNpmCompilers(cfg.npm.compilers);\n        deppack.setPlugins(plugins, cfg.npm.compilers);\n\n        return Promise.all(this.hooks.preCompile()).then(() => {\n          this.initWatcher(watchedPaths);\n          this.initCompilation();\n        });\n      })\n      .catch(error => {\n        if (typeof error === 'string') {\n          // TODO: Title - init error.\n          logger.error(error);\n        } else {\n          const text = error.code === 'CFG_LOAD_FAILED' ?\n            error.message :\n            `Initialization error - ${error.message.trim()}`;\n          // TODO: Title - init error.\n          logger.error(text, error);\n        }\n        process.exit(1);\n      });\n  }\n\n  initCompilation() {\n    const cfg = this.config;\n\n    this.fileList = new FileList(cfg);\n    this.fileList.on('ready', () => {\n      if (this._startTime) {\n        this.compile();\n      }\n    });\n\n    const rootPath = cfg.paths.root;\n    this.plugins.includes.forEach(path => {\n      const relPath = getRelativePath(rootPath, path);\n\n      // Emit `change` event for each file that is included with plugins.\n      this.startCompilation('change', relPath);\n      cfg.npm.static.push(relPath);\n    });\n\n    Object.freeze(cfg.npm.static);\n\n    if (!cfg.persistent) return;\n\n    const emptyFileListInterval = 1000;\n    const checkNothingToCompile = () => {\n      if (!this.fileList.hasFiles) {\n        logger.warn(`Nothing to compile. Most likely you don't have any source files yet, in which case, go ahead and create some!`);\n      }\n    };\n\n    clearTimeout(this.nothingToCompileTimer);\n    this.nothingToCompileTimer = setTimeout(checkNothingToCompile, emptyFileListInterval);\n\n    if (cfg.stdin) {\n      process.stdin.on('end', () => process.exit(0));\n      process.stdin.resume();\n    }\n  }\n\n  exitProcessFromFile(reasonFile) {\n    logger.info(`Detected removal of ${reasonFile}\\nExiting.`);\n    process.exit(0);\n  }\n\n  initWatcher(watchedPaths) {\n    const isDebug = !!process.env.DEBUG;\n    const config = this.config._normalized;\n    const paths = config.paths;\n    const isConfig = path => paths.allConfigFiles.includes(path);\n\n    speed.profile('Loaded watcher');\n    this.watcher = chokidar.watch(watchedPaths, Object.assign({\n      ignored,\n      persistent: config.persistent,\n    }, config.watcher))\n      .on('error', error => {\n        // TODO: Watch error.\n        logger.error(error);\n      })\n      .on('add', absPath => {\n        if (isDebug) debug(`add ${absPath}`);\n\n        const path = getRelativePath(paths.root, absPath);\n        if (isConfig(path)) return; // Pass for the initial files.\n        this.startCompilation('change', path);\n      })\n      .on('change', absPath => {\n        if (isDebug) debug(`change ${absPath}`);\n\n        const path = getRelativePath(paths.root, absPath);\n        if (path === paths.packageConfig) {\n          this.restartBrunch('package');\n        } else if (path === paths.bowerConfig) {\n          this.restartBrunch('bower');\n        } else if (isConfig(path)) {\n          this.restartBrunch();\n        } else {\n          this.startCompilation('change', path);\n        }\n      })\n      .on('unlink', absPath => {\n        if (isDebug) debug(`unlink ${absPath}`);\n\n        const path = getRelativePath(paths.root, absPath);\n        if (isConfig(path)) return this.exitProcessFromFile(path);\n        this.startCompilation('unlink', path);\n      })\n      .once('ready', () => {\n        speed.profile('Watcher is ready');\n        this.watcherIsReady = true;\n      });\n  }\n\n  restartBrunch(pkgType) {\n    const restart = () => {\n      // we need this to keep compatibility with global `brunch` binaries\n      // from older versions which didn't create a child process\n      if (process.send && process.env.BRUNCH_FORKED_PROCESS === 'true') {\n        process.send('reload');\n      } else {\n        const opts = this._constructorOptions;\n        const newWatcher = new BrunchWatcher(opts[0], opts[1], opts[2]);\n        if (this._onReload) this._onReload(newWatcher);\n        return newWatcher;\n      }\n    };\n\n    const rootPath = this.config.paths.root;\n    const reWatch = () => {\n      logger.info('Reloading watcher...');\n      this.hooks.teardown();\n      const server = this.server;\n      if (server && typeof server.close === 'function') {\n        return server.close(restart);\n      }\n      return restart();\n    };\n\n    clearTimeout(this.nothingToCompileTimer);\n    this.fileList.dispose();\n    this.watcher.close();\n    workers.close();\n\n    return install({rootPath, pkgType}).then(reWatch, reWatch);\n  }\n\n  compile() {\n    const startTime = this._endCompilation();\n    const config = this.config;\n    const joinConfig = config._normalized.join;\n    const fileList = this.fileList;\n    const watcher = this.watcher;\n    const optimizers = this.plugins.optimizers;\n\n    const assetErrors = fileList.assetErrors;\n    if (assetErrors.length) {\n      assetErrors.forEach(error => {\n        // TODO: Title - asset processing error\n        logger.error(error);\n      });\n      return;\n    }\n\n    // Determine which files has been changed,\n    // create new `fs_utils.GeneratedFile` instances and write them.\n    write(fileList, config, joinConfig, optimizers, startTime).then(data => {\n      const generatedFiles = data.changed;\n      const disposed = data.disposed;\n      fileList.removeDisposedFiles();\n      this._endBundle();\n      const assets = fileList.copiedAfter(startTime);\n      logger.info(helpers.generateCompilationLog(\n        startTime, assets, generatedFiles, disposed\n      ));\n\n      // Pass `fs_utils.GeneratedFile` instances to callbacks.\n      // Does not block the execution.\n      this.hooks.onCompile(generatedFiles, assets);\n    }, error => {\n      this._endBundle();\n      if (error.code === 'WRITE_FAILED') return; // Ignore write errors as they are logged already\n\n      if (!Array.isArray(error)) error = [error];\n\n      // Compilation, optimization, linting errors are logged here.\n      error.forEach(subError => {\n        // TODO: Title - pipeline error.\n        logger.error(subError);\n      });\n\n      const canTryRecover = error.find(err => err.code === 'DEPS_RESOLVE_INSTALL');\n      if (canTryRecover) {\n        logger.warn('Attempting to recover from failed NPM requires by running `npm install`...');\n        this.restartBrunch('package');\n      }\n    }).then(() => {\n      if (!this.watcherIsReady) return;\n      // If it’s single non-continuous build, close file watcher and\n      // exit process with correct exit code.\n      if (!config.persistent) {\n        watcher.close();\n        workers.close();\n      }\n      fileList.initial = false;\n    }).catch(logger.error);\n  }\n\n  _createProgress() {\n    if (this._compilationProgress || process.env.DEBUG) return false;\n    const passedTime = this._isFirstRun && speed.sinceStart;\n    this._compilationProgress = helpers.getCompilationProgress(\n      passedTime, logger.info\n    );\n  }\n\n  // Set start time of last compilation to current time.\n  // Returns number.\n  startCompilation(type, path) {\n    this.fileList.emit(type, path);\n    this._createProgress();\n    if (this._isFirstRun) {\n      speed.profile('Starting compilation');\n      this._isFirstRun = false;\n    }\n    if (!this._startTime) this._startTime = Date.now();\n    return this._startTime;\n  }\n\n  // Get last compilation start time and reset the state.\n  // Returns number.\n  _endCompilation() {\n    const start = this._startTime;\n    this._startTime = null;\n    return start;\n  }\n\n  _endBundle() {\n    if (!this._compilationProgress) return;\n    this._compilationProgress();\n    this._compilationProgress = null;\n  }\n}\n\nconst watch = (persistent, path, options, onCompile) => {\n  if (!onCompile) onCompile = () => {};\n\n  // If path isn't provided (by CLI).\n  if (path) {\n    if (typeof path === 'string') {\n      process.chdir(path);\n    } else {\n      if (typeof options === 'function') onCompile = options;\n      options = path;\n    }\n  }\n  return new BrunchWatcher(persistent, options, onCompile);\n};\n\nmodule.exports = watch;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/workers/index.js":"'use strict';\nconst WorkerManager = require('./manager');\nconst jobs = require('./jobs');\n\nlet manager;\n\nconst cleanError = (error, coerce) => {\n  const err = typeof error === 'string' ? new Error(error) : error;\n  const data = coerce ? {error: err.message} : new Error(err.message);\n  data.name = '';\n  data.stack = err.stack;\n  return data;\n};\n\n/*\n * A job is described by:\n *\n * - `serialize`, which takes some hash and produces a hash to be sent as JSON (always executed in main process);\n * - `deserialize`, which takes the hash from the step above and should produce the original hash passed to serialize (always executed in worker process). To aid reconstructing original hash, ctx is passed (which contains all loaded plugins; we needed it to select appropriate plugins for a given file to compile)\n * - `work`: actually perform the work, can be called in both master and worker.\n */\n\n// Schedule a job for processing. If workers are enabled, will schedule that.\n// Otherwise, just run the work function.\nexports.processJob = (job, hash) => {\n  if (typeof job === 'string') job = jobs[job];\n  if (manager) {\n    return manager.schedule(job.path, {hash: job.serialize(hash)});\n  }\n  return job.work(hash).then(null, error => {\n    throw cleanError(error);\n  });\n};\n\nexports.init = (options, cfg) => {\n  manager = new WorkerManager(options, cfg);\n};\n\nexports.close = () => {\n  if (manager) {\n    manager.close();\n    manager = null;\n  }\n};\n\nexports.parallel = (id, fn) => {\n  return fn;\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/workers/manager.js":"'use strict';\nconst fork = require('child_process').fork;\nconst EventEmitter = require('events');\nconst debug = require('debug')('brunch:workers');\n\nconst workerFile = `${__dirname}/job-processor.js`;\n\nconst genId = (() => {\n  let counter = 0;\n\n  return () => counter++;\n})();\n\nclass WorkerManager {\n  constructor(options, config) {\n    this.jobs = [];\n    this.workers = [];\n    this.pending = {};\n    this.events = new EventEmitter();\n    this.options = options;\n    this.config = config;\n\n    let jobs = options.jobs;\n    debug(`Spinning ${jobs} workers`);\n    while (jobs--) this.fork();\n    this._checker = setInterval(() => this.sendMessage());\n  }\n\n  fork() {\n    const list = this.workers;\n    const pending = this.pending;\n    // remove the circular reference in parsed options\n    const options = Object.assign({}, this.options, {parent: null});\n    // pass parsed options to not make each worker parse the options\n    const workerEnv = {BRUNCH_OPTIONS: JSON.stringify(options)};\n    const env = Object.assign({}, process.env, workerEnv);\n    const worker = fork(workerFile, {env});\n    const events = this.events;\n    let idx;\n    worker.on('message', msg => {\n      if (msg === 'ready') {\n        list.push(worker);\n        idx = list.indexOf(worker);\n        debug(`Worker ${idx} spawned`);\n        pending[idx] = false;\n      } else {\n        const id = pending[idx];\n        pending[idx] = false;\n        events.emit(id, msg);\n      }\n    });\n  }\n\n  close() {\n    debug('Killing workers');\n    clearInterval(this._checker);\n    this.workers.forEach(worker => worker.kill('SIGINT'));\n  }\n\n  // schedule a `type` operation with `data` for processing\n  // returns a promise which will yield the results of the computation\n  schedule(type, data) {\n    const id = genId();\n    this.jobs.push([id, {type, data}]);\n\n    return new Promise((resolve, reject) => {\n      this.events.once(id, response => {\n        if ('result' in response) {\n          resolve(response.result);\n        } else {\n          const error = new Error(response.error);\n          error.name = '';\n          if (response.stack) {\n            error.stack = `\\nWorker ${response.stack}\\n\\nMain thread ${error.stack}`;\n          }\n          reject(error);\n        }\n      });\n    });\n  }\n\n  get freeWorkerIdx() {\n    return Object.keys(this.workers).find(idx => this.pending[idx] === false);\n  }\n\n  sendMessage() {\n    const workerIdx = this.freeWorkerIdx;\n    if (!workerIdx) return;\n    const job = this.jobs.pop();\n    if (!job) return;\n    const worker = this.workers[workerIdx];\n\n    const id = job[0];\n    const data = job[1];\n\n    this.pending[workerIdx] = id;\n    worker.send(data);\n  }\n}\n\nmodule.exports = WorkerManager;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/workers/jobs.js":"'use strict';\n\nconst smap = require('source-map');\nconst SourceMapConsumer = smap.SourceMapConsumer;\nconst SourceMapGenerator = smap.SourceMapGenerator;\n\nexports.OptimizeJob = {\n  path: 'OptimizeJob',\n\n  serialize(hash) {\n    const optimizer = hash.optimizer.brunchPluginName;\n    const params = hash.params;\n    return {optimizer, params: {data: params.data, map: params.map, path: params.path}};\n  },\n\n  deserialize(ctx, hash) {\n    const optimizer = ctx.plugins.optimizers.find(p => p.brunchPluginName === hash.optimizer);\n\n    const deserializeSourceMap = serializedMap => {\n      return SourceMapGenerator.fromSourceMap(new SourceMapConsumer(serializedMap));\n    };\n\n    const params = hash.params;\n    params.map = deserializeSourceMap(params.map);\n\n    return {optimizer, params};\n  },\n\n  work(hash) {\n    const optimizer = hash.optimizer;\n    const file = hash.params;\n\n    return optimizer.optimize(file);\n  },\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/write.js":"'use strict';\nconst debug = require('debug')('brunch:write');\nconst sysPath = require('universal-path');\nconst logger = require('loggy');\n\nconst deppack = require('deppack'); // getAllDependents\nconst formatError = require('../utils/helpers').formatError;\nconst generate = require('./generate');\nconst BrunchError = require('../utils/error');\n\n// For use in `.filter()`.\nconst changedSince = startTime => generated => {\n  return generated.allSourceFiles.some(f => f.compilationTime >= startTime || f.removed);\n};\n\nconst getPaths = (type, isHelper, path, sourceFileJoinConfig) => {\n  const helpers = sourceFileJoinConfig.pluginHelpers;\n  return Object.keys(sourceFileJoinConfig)\n    .filter(key /* generatedFilePath */ => {\n      if (key === 'pluginHelpers') return;\n      if (isHelper) return helpers.includes(key);\n\n      const checker = sourceFileJoinConfig[key];\n      return checker(path);\n    });\n};\n\nconst filterTargetsForEntry = (files, type, entry) => {\n  const makeTarget = (file, target) => {\n    if (file.error == null && target.data == null) return;\n    const mainTarget = file.type === type;\n    return {\n      path: file.path,\n      data: target.data,\n      node: target.node,\n      type,\n      isHelper: file.isHelper,\n      source: mainTarget ? file.source : target.data,\n      file,\n    };\n  };\n\n  const targets = files.reduce((targets, file) => {\n    const rawTarget = file.targets[type];\n    if (rawTarget) {\n      targets.push(makeTarget(file, rawTarget));\n    }\n    return targets;\n  }, []);\n\n  // special entry point for joinTo - return all targets of matching type\n  if (entry === '*') return targets;\n  // otherwise, if normal entry point, gather its deps\n  const depPaths = deppack.getAllDependents(entry);\n  return targets.filter(t => depPaths.includes(t.path));\n};\n\nconst getFiles = (fileList, config, joinConfig) => {\n  const _targetMap = {};\n\n  Object.keys(joinConfig).forEach(type => {\n    const entryPoints = joinConfig[type];\n\n    Object.keys(entryPoints).map(entry => {\n      const subCfg = entryPoints[entry];\n\n      const ftype = type.slice(0, -1); // javascripts -> javascript\n      const allFiles = Array.from(fileList.files.values());\n      const targets = filterTargetsForEntry(allFiles, ftype, entry);\n      targets.forEach(target => {\n        const paths = getPaths(target.type, target.isHelper, target.path, subCfg);\n        paths.forEach(path => {\n          if (_targetMap[path] == null) _targetMap[path] = [];\n          _targetMap[path].push(target);\n        });\n      });\n    });\n  });\n\n  return Object.keys(_targetMap).map(generatedFilePath => {\n    const targets = _targetMap[generatedFilePath];\n    const allSourceFiles = targets.map(target => target.file);\n    const type = targets[0] && targets[0].type;\n    const isJs = type => type === 'javascript' || type === 'template';\n    const sourceFiles = type ?\n      allSourceFiles.filter(f => f.type === type || isJs(f.type) && isJs(type)) :\n      [];\n    const path = sysPath.join(config.paths.public, generatedFilePath);\n    return {allSourceFiles, sourceFiles, path, targets, type};\n  });\n};\n\nconst checkWritten = (fileList, files, startTime) => {\n  const allWrittenTargets = {};\n  files.map(file => {\n    file.targets.forEach(target => {\n      if (!allWrittenTargets[target.type]) allWrittenTargets[target.type] = [];\n      allWrittenTargets[target.type].push(target.path);\n    });\n  });\n\n  fileList.files.forEach(file => {\n    if (file.error) logger.error(formatError(file));\n    if (file.compilationTime >= startTime) {\n      Object.keys(file.targets).forEach(type => {\n        if (!type) return;\n        const target = file.targets[type];\n        const allTargets = allWrittenTargets[type] || [];\n        if (!allTargets.includes(file.path) && target.data) {\n          logger.warn(`${file.path} compiled, but not written. Check your ${type}s.joinTo config`);\n        }\n      });\n    }\n  });\n};\n\nconst writeStatic = (fileList, config, startTime) => {\n  const assetErrors = fileList.assetErrors;\n  if (assetErrors.length) throw assetErrors.join(' ; ');\n\n  const assets = Array.from(fileList.assets.values());\n  const changed = assets.filter(f => f.compilationTime >= startTime || f.removed);\n  const toRemove = changed.filter(f => f.removed);\n  const toWrite = changed.filter(f => !f.removed);\n\n  debug(`Writing ${toWrite.length}/${assets.length} assets, removing ${toRemove.length}`);\n\n  return generate.writeStatics(toRemove, toWrite);\n};\n\nconst write = (fileList, config, joinConfig, optimizers, startTime) => {\n  const files = getFiles(fileList, config, joinConfig);\n  checkWritten(fileList, files, startTime);\n  const errors = files\n    .map(generated => {\n      return generated.sourceFiles\n        .filter(f => f.error != null)\n        .map(formatError);\n    })\n    .reduce((a, b) => a.concat(b), []);\n\n  if (errors.length) {\n    const error = errors.join(' ; ');\n    return Promise.reject(new BrunchError('WRITE_FAILED', {error}));\n  }\n\n  const changed = files.filter(changedSince(startTime));\n  debug(`Writing ${changed.length}/${files.length} files`);\n\n  // Remove files marked as such and dispose them, clean memory.\n  const disposed = {generated: [], sourcePaths: []};\n  changed.forEach(generated => {\n    const sourceFiles = generated.allSourceFiles;\n    sourceFiles\n      .filter(file => file.removed)\n      .forEach(file => {\n        disposed.generated.push(generated);\n        disposed.sourcePaths.push(sysPath.basename(file.path));\n        file.dispose();\n      });\n\n    generated.targets = generated.targets.filter(x => !x.file.disposed);\n  });\n\n  return Promise.all(changed.map(file => {\n    return generate(file.path, file.targets, config, optimizers);\n  })).then(() => {\n    return writeStatic(fileList, config, startTime);\n  }).then(() => {\n    return {changed, disposed};\n  });\n};\n\nmodule.exports = write;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/helpers.js":"'use strict';\nconst basename = require('universal-path').basename;\nconst promisify = require('micro-promisify');\nconst fslstat = promisify(require('fs').lstat);\nconst fsaccess = promisify(require('fs').access);\n\n// Single-level flatten.\nconst flatten = array => [].concat.apply([], array);\n\nconst deepAssign = (target, source, filter) => {\n  const shouldMerge = typeof filter === 'function' &&\n    filter(target, source) ||\n    (() => true);\n\n  Object.keys(source).forEach(key => {\n    const value = source[key];\n    const isObject = toString.call(value) === '[object Object]';\n    if (isObject && shouldMerge(key, value)) {\n      let nested = target[key];\n      if (nested == null) nested = target[key] = {};\n      deepAssign(nested, value, filter);\n    } else {\n      target[key] = value;\n    }\n  });\n\n  return target;\n};\n\nconst asyncFilter = (arr, fn) => {\n  const promises = arr.map(item => fn(item).then(result => [item, result]));\n  return Promise.all(promises).then(data => {\n    return data.filter(x => x[1]).map(x => x[0]);\n  });\n};\n\nconst prettify = object => {\n  return Object.entries(object).map(pair => pair.join('=')).join(' ');\n};\n\nconst getFormattedError = (err, code, path) => {\n  let error;\n  if (typeof err === 'string') {\n    error = new Error(err);\n  } else {\n    error = new Error(err.toString());\n    error.stack = err.stack;\n  }\n  error.name = '';\n  const message = error.message.trim().replace(/^/gm, '   ').trim();\n\n  error.message = `${code || 'Processing'} of ${path} failed. ${message}`;\n  return error;\n};\n\nconst formatError = file => {\n  return getFormattedError(file.error, file.error.pipelineCode, file.path);\n};\n\nconst formatOptimizerError = (error, path) => {\n  return getFormattedError(error, 'Optimizing', path);\n};\n\n/* compiled 4 files and 145 cached files into app.js\n * compiled app.js and 10 cached files into app.js, copied 2 files\n * `compiled 106 into 3 and copied 47 files` - initial compilation\n * `copied img.png` - 1 new/changed asset\n * `copied 6 files` - >1 new/changed asset\n * `compiled controller.coffee and 32 cached files into app.js`\n * `compiled _partial.styl and 22 cached into 2 files` - 1 partial affecting\n *                                                      >1 compiled file\n * `compiled init.ls into init.js` - 1 source file that doesn't\n *                                   concat with any other files\n * `compiled 5 files into ie7.css` - source files that go into 1 compiled\n * `compiled 2 and 3 cached files into ie7.css` - change some source files\n *                                                that go into 1 compiled\n * `compiled 4 files and 1 cached into ie7.css` - one cached should not\n *                                                switch to filename\n * `compiled 5 and 101 cached into 3 files` - change >1 affecting >1 compiled\n */\nconst generateCompilationLog = (startTime, copiedAssets, generatedFiles, disposedFiles) => {\n  const getName = file => basename(file.path);\n  const copied = copiedAssets.map(getName);\n  const generated = [];\n  const compiled = [];\n  let cachedCount = 0;\n  const dgen = disposedFiles.generated;\n  generatedFiles.forEach(generatedFile => {\n    let isChanged = false;\n    let locallyCompiledCount = 0;\n    const len = generatedFile.sourceFiles.length;\n    generatedFile.sourceFiles.forEach(sourceFile => {\n      if (sourceFile.compilationTime >= startTime) {\n        isChanged = true;\n        locallyCompiledCount++;\n        const sourceName = getName(sourceFile);\n        if (!compiled.includes(sourceName)) {\n          compiled.push(sourceName);\n        }\n      }\n      if (!isChanged && dgen.includes(generatedFile)) isChanged = true;\n    });\n    if (isChanged) {\n      generated.push(getName(generatedFile));\n      cachedCount += len - locallyCompiledCount;\n    }\n  });\n  const disposed = disposedFiles.sourcePaths;\n  const generatedLog = (() => {\n    switch (generated.length) {\n      case 0: return '';\n      case 1: return ` into ${generated}`;\n    }\n    return ` into ${generated.length} files`;\n  })();\n  const compiledLog = (() => {\n    switch (compiled.length) {\n      case 0:\n        switch (disposed.length) {\n          case 0: return '';\n          case 1: return `removed ${disposed}`;\n        }\n        return `removed ${disposed.length}`;\n      case 1:\n        return `compiled ${compiled}`;\n    }\n    return `compiled ${compiled.length}`;\n  })();\n  const cachedLog = (() => {\n    if (cachedCount === 0) return compiled.length <= 1 ? '' : ' files';\n\n    switch (compiled.length) {\n      case 0:\n        const noun = generated.length > 1 ? '' : ' files';\n        return ` and wrote ${cachedCount} cached${noun}`;\n      case 1:\n        const cachedCountName = `file${cachedCount === 1 ? '' : 's'}`;\n        return ` and ${cachedCount} cached ${cachedCountName}`;\n    }\n    return ` files and ${cachedCount} cached`;\n  })();\n  const nonAssetsLog = compiledLog + cachedLog + generatedLog;\n  const sep = nonAssetsLog && copied.length ? ', ' : '';\n  const assetsLog = (() => {\n    switch (copied.length) {\n      case 0: return '';\n      case 1: return `copied ${copied}`;\n    }\n    return compiled.length ?\n      `copied ${copied.length}` :\n      `copied ${copied.length} files`;\n  })();\n  const main = nonAssetsLog + sep + assetsLog;\n  const diff = Date.now() - startTime;\n  const oneSecond = 1000;\n  const diffText = diff > oneSecond ?\n    `${(diff / oneSecond).toFixed(1)} sec` :\n    `${diff} ms`;\n  return `${main || 'compiled'} in ${diffText}`;\n};\n\nconst animationLogInterval = 4000;\n\nconst getCompilationProgress = (timePassed, logger) => {\n  if (!timePassed) timePassed = 0;\n  let iterations = 0;\n  let timeout;\n  let initRunIn = timePassed ?\n    animationLogInterval - timePassed :\n    animationLogInterval;\n  if (initRunIn < 0) initRunIn = 0;\n\n  const writeWithDots = () => {\n    const msg = iterations === 7 ? 'still compiling' : 'compiling';\n    const line = msg + '.'.repeat(iterations % 4);\n    logger(line);\n    iterations++;\n    timeout = setTimeout(writeWithDots, animationLogInterval);\n  };\n\n  timeout = setTimeout(writeWithDots, initRunIn);\n  return () => clearTimeout(timeout);\n};\n\nconst deepFreeze = (object, except) => {\n  Object.freeze(object);\n\n  for (const key of Object.keys(object)) {\n    if (except && except.includes(key)) continue;\n\n    const value = object[key];\n    if (value instanceof RegExp) continue;\n    if (!Object.isFrozen(value)) {\n      deepFreeze(value, except);\n    }\n  }\n\n  return object;\n};\n\nconst fsExists = path => {\n  return fsaccess(path).then(() => true, () => false);\n};\n\nconst isSymlink = path => {\n  return fslstat(path).then(stat => stat.isSymbolicLink(), () => false);\n};\n\nconst promiseReduce = (array, callback, initial) => {\n  return array.reduce((promise, item) => {\n    return promise.then(callback(item));\n  }, Promise.resolve(initial));\n};\n\nclass FrozenMap extends Map {\n  set(key) {\n    throw new TypeError(`Can't set property '${key}', map is not extensible`);\n  }\n}\n\nclass FrozenSet extends Set {\n  add(value) {\n    throw new TypeError(`Can't add value '${value}', set is not extensible`);\n  }\n}\n\nconst pull = (array, is) => {\n  const index = array.findIndex(is);\n  if (index === -1) return;\n\n  const item = array[index];\n  array.splice(index, 1);\n  return item;\n};\n\nmodule.exports = {\n  flatten,\n  deepAssign,\n  asyncFilter,\n  prettify,\n  formatError,\n  formatOptimizerError,\n  generateCompilationLog,\n  getCompilationProgress,\n  deepFreeze,\n  fsExists,\n  isSymlink,\n  promiseReduce,\n  FrozenMap,\n  FrozenSet,\n  pull,\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/generate.js":"'use strict';\nconst debug = require('debug')('brunch:generate');\nconst sysPath = require('universal-path');\nconst anysort = require('anysort');\nconst promisify = require('micro-promisify');\nconst fsWriteFile = promisify(require('fs').writeFile);\nconst mkdirp = promisify(require('mkdirp'));\nconst unlink = promisify(require('fs').unlink);\nconst deppack = require('deppack'); // needsProcessing, processFiles\nconst helpers = require('../utils/helpers');\nconst flatten = helpers.flatten;\nconst promiseReduce = helpers.promiseReduce;\nconst formatOptimizerError = helpers.formatOptimizerError;\nconst processJob = require('../workers').processJob;\nconst hmr = require('../utils/hmr'); // isEnabled, generate\nconst BrunchError = require('../utils/error');\n\nconst smap = require('source-map');\nconst SourceMapConsumer = smap.SourceMapConsumer;\nconst SourceMapGenerator = smap.SourceMapGenerator;\nconst SourceNode = smap.SourceNode;\n\n// Generate: [File] -> File.\n// Takes a list of files (FileList) and makes one output from it.\n\n// Writes data into a file.\n// Creates the file and/or all parent directories if they don't exist.\n// Returns a promise (not valued if success).\nconst writeFile = (path, data) => {\n  debug(`Writing ${path}`);\n  const write = () => fsWriteFile(path, data);\n  const rwxrxrx = 0o755;\n\n  return write().catch(() => {\n    return mkdirp(sysPath.dirname(path), rwxrxrx).then(write);\n  });\n};\n\n// Sorts by pattern.\n// sort(['b.coffee', 'c.coffee', 'a.coffee'], {before: ['a.coffee'], after: ['b.coffee']})\n// => ['a.coffee', 'c.coffee', 'b.coffee']\n// Returns new sorted array.\nconst sortByConfig = (files, config) => {\n  if (toString.call(config) !== '[object Object]') return files;\n  const criteria = [\n    config.before || [],\n    config.after || [],\n    config.joinToValue || [],\n    config.bower || [],\n    config.vendorConvention || (() => false),\n  ];\n  return anysort.grouped(files, criteria, [0, 2, 3, 4, 5, 1]);\n};\n\nconst extractOrder = (files, config) => {\n  const types = files.map(file => `${file.type}s`);\n  const orders = Object.keys(config.files)\n    .filter(key => types.includes(key))\n    .map(key => config.files[key].order || {});\n  const before = flatten(orders.map(type => type.before || []));\n  const after = flatten(orders.map(type => type.after || []));\n  const norm = config._normalized;\n  const vendorConvention = norm.conventions.vendor;\n  const bower = norm.packageInfo.bower.order;\n  return {before, after, vendorConvention, bower};\n};\n\nconst sort = (files, config, joinToValue) => {\n  const paths = files.map(file => file.path);\n  const indexes = Object.create(null);\n  files.forEach(file => {\n    indexes[file.path] = file;\n  });\n  const order = extractOrder(files, config);\n  if (Array.isArray(joinToValue)) order.joinToValue = joinToValue;\n  return sortByConfig(paths, order).map(path => indexes[path]);\n};\n\nconst concat = (files, path, definitionFn, autoRequire, config) => {\n  if (autoRequire == null) autoRequire = [];\n  const isJs = !!definitionFn;\n\n  const root = new SourceNode();\n  const str = files.map(f => f.path).join(', ');\n  debug(`Concatenating [${str}] => ${path}`);\n\n  const processor = file => {\n    root.add(file.node);\n    const data = file.node.isIdentity ? file.data : file.source;\n    if (isJs && !/;\\s*$/.test(data)) root.add(';');\n    return root.setSourceContent(file.node.source, data);\n  };\n\n  if (isJs) {\n    const addRequire = req => root.add(`require('${req}');`);\n\n    const isNpm = config.npm.enabled ? deppack.needsProcessing : () => false;\n    const isHmr = hmr.isEnabled(config);\n\n    const moduleFiles = files.filter(f => isNpm(f) || f.file.isModule);\n    const nonModuleFiles = files.filter(f => !moduleFiles.includes(f));\n\n    const definition = definitionFn(path, root.sourceContents);\n    const generateModuleFiles = () => {\n      if (config.npm.enabled && moduleFiles.length) {\n        deppack.processFiles(root, moduleFiles, processor);\n      } else {\n        moduleFiles.forEach(processor);\n      }\n    };\n\n    const basicGenerate = (generateModuleFiles, nonModuleFiles, processor, deppack, definition, path, root) => {\n      root.add(definition);\n      generateModuleFiles();\n      nonModuleFiles.forEach(processor);\n    };\n\n    const generator = isHmr ? hmr.generate : basicGenerate;\n    generator(generateModuleFiles, nonModuleFiles, processor, deppack, definition, path, root);\n\n    autoRequire.forEach(addRequire);\n  } else {\n    files.forEach(processor);\n  }\n  return root.toStringWithSourceMap({file: path});\n};\n\nconst prepareSourceMap = (optimizedMap, sourceFiles) => {\n  if (optimizedMap == null) return;\n  const map = SourceMapGenerator.fromSourceMap(new SourceMapConsumer(optimizedMap));\n  if (map._sourcesContents == null) map._sourcesContents = {};\n  sourceFiles.forEach(arg => {\n    const path = arg.path;\n    const source = arg.source;\n    map._sourcesContents[path] = source;\n  });\n  return map;\n};\n\nconst runOptimizer = optimizer => params => {\n  if (!params) {\n    throw new BrunchError('OPTIMIZER_INVALID', {optimizer});\n  }\n  const unoptMap = params.map;\n  const path = params.path;\n  const sourceFiles = params.sourceFiles;\n  debug(`Optimizing ${path} @ ${optimizer.brunchPluginName}`);\n\n  return processJob('OptimizeJob', {optimizer, params}).then(optimized => {\n    const data = optimized.data;\n    const map = prepareSourceMap(optimized.map, sourceFiles) || unoptMap;\n    return {data, path, map, sourceFiles, code: data};\n  }, error => {\n    throw formatOptimizerError(error, path);\n  });\n};\n\nconst optimize = (data, map, path, optimizers, sourceFiles) => {\n  const initial = {data, path, map, sourceFiles, code: data};\n  return promiseReduce(optimizers, runOptimizer, initial);\n};\n\nconst getInlineSourceMapUrl = map => {\n  const base64String = new Buffer(JSON.stringify(map)).toString('base64');\n  return `data:application/json;charset=utf-8;base64,${base64String}`;\n};\n\nconst jsTypes = ['javascript', 'template'];\n\nconst generate = (path, targets, config, optimizers) => {\n  const type = targets.some(file => jsTypes.includes(file.type)) ?\n    'javascript' : 'stylesheet';\n\n  const foptim = optimizers.filter(optimizer => optimizer.type === type);\n  const joinKey = path.slice(config.paths.public.length + 1);\n  const typeConfig = config.files[`${type}s`] || {};\n  const joinToValue = typeConfig.joinTo && typeConfig.joinTo[joinKey] || {};\n  const sorted = sort(targets, config, joinToValue);\n  const norm = config._normalized;\n  const definition = type === 'javascript' ? norm.modules.definition : null;\n  const cc = concat(\n    sorted, path, definition,\n    norm.modules.autoRequire[joinKey],\n    config\n  );\n  const code = cc.code;\n  const map = cc.map;\n  const withMaps = map && config.sourceMaps;\n  const mapPath = `${path}.map`;\n  return optimize(code, map, path, foptim, targets)\n    .then(data => {\n      if (withMaps) {\n        const mapRoute = config.sourceMaps === 'inline' ?\n          getInlineSourceMapUrl(data.map) :\n          config.sourceMaps === 'absoluteUrl' ?\n          mapPath.replace(config.paths.public, '') :\n          sysPath.basename(mapPath);\n        const controlChar = config.sourceMaps === 'old' ? '@' : '#';\n        const end = `${controlChar} sourceMappingURL=${mapRoute}`;\n        data.code += type === 'javascript' ? `\\n//${end}` : `\\n/*${end}*/`;\n      }\n      return data;\n    })\n    .then(data => {\n      return Promise.all([\n        writeFile(path, data.code),\n        withMaps && config.sourceMaps !== 'inline' && writeFile(mapPath, data.map.toString()),\n      ]).then(() => data);\n    });\n};\n\ngenerate.writeFile = writeFile;\n\ngenerate.writeStatics = (toRemove, toWrite) => {\n  const removePromise = promiseReduce(toRemove, file => {\n    file.dispose();\n    return () => unlink(file.destinationPath);\n  });\n\n  const writePromise = promiseReduce(toWrite, file => {\n    return () => writeFile(file.destinationPath, file.compiled);\n  });\n\n  return removePromise.then(() => writePromise);\n};\n\ngenerate.sortByConfig = sortByConfig;\n\nmodule.exports = generate;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/hmr.js":"'use strict';\n\nconst sysPath = require('universal-path');\nconst logger = require('loggy');\n\nexports.isEnabled = config => config.hot && !config.env.includes('production');\nexports.generate = (generateModuleFiles, nonModuleFiles, processor, deppack, definition, path, root) => {\n  const hmrPath = sysPath.join('hmr-brunch', 'runtime.js');\n  const hmrFile = nonModuleFiles.find(f => f.path.includes(hmrPath));\n\n  if (hmrFile) {\n    processor(hmrFile);\n  } else {\n    logger.warn(`HMR runtime not found for ${path}. HMR only works if use compile your JS into a single file, could it be the case?`);\n  }\n\n  root.add(definition);\n\n  const depGraph = JSON.stringify(deppack.graph());\n  root.add(`require.hmr(${depGraph}, function(require) {\\n`);\n\n  generateModuleFiles();\n\n  root.add('});');\n  root.add('// hmr end');\n\n  nonModuleFiles.filter(f => f !== hmrFile).forEach(processor);\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/is_ignored.js":"'use strict';\nconst basename = require('universal-path').basename;\n\n// RegExps that filter out invalid files (dotfiles, emacs caches etc).\nconst apacheRe = /\\.(?!htaccess|rewrite)/;\nconst dotfilesRe = /(^[.#]|(?:__|~)$)/;\n\nmodule.exports = path => {\n  const name = basename(path);\n  return apacheRe.test(name) && dotfilesRe.test(name);\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/file_list.js":"'use strict';\nconst debug = require('debug')('brunch:list');\nconst EventEmitter = require('events');\nconst readAndCache = require('fcache').updateCache;\nconst formatError = require('../utils/helpers').formatError;\nconst FrozenMap = require('../utils/helpers').FrozenMap;\nconst FrozenSet = require('../utils/helpers').FrozenSet;\nconst Asset = require('./asset');\nconst SourceFile = require('./source_file');\nconst BrunchError = require('../utils/error');\nconst anymatch = require('anymatch');\n\n// A list of `fs_utils.SourceFile` or `fs_utils.Asset` that contains *all* file\n// from Brunches app with some additional methods used to simplify file reading / removing.\nclass FileList extends EventEmitter {\n  constructor(config) {\n    super();\n\n    // Maximum time between changes of two files that\n    // will be considered as a one compilation.\n    this.resetTime = config.fileListInterval;\n\n    const norm = config._normalized;\n\n    // Grab values from config.\n    this.publicPath = norm.paths.public;\n    this.conventions = norm.conventions;\n    this.moduleWrapper = norm.modules.wrapper;\n\n    this.files = new Map();\n    this.assets = new Map();\n\n    this.reading = new Map();\n    this.compiling = new Set();\n    this.compiled = new Set();\n\n    this.timer = null;\n    this.initial = true;\n    this.disposed = false;\n\n    this.on('change', this._change);\n    this.on('unlink', this._unlink);\n\n    // Disallow adding new properties and changing descriptors.\n    Object.seal(this);\n  }\n\n  get assetErrors() {\n    return Array.from(this.assets.values()).filter(file => file.error).map(formatError);\n  }\n\n  get hasFiles() {\n    return !!(this.files.size || this.assets.size);\n  }\n\n  get hasPendingFiles() {\n    return !!(this.reading.size || this.compiling.size);\n  }\n\n  copiedAfter(time) {\n    return Array.from(this.assets.values()).filter(asset => {\n      return asset.copyTime > time;\n    });\n  }\n\n  removeDisposedFiles() {\n    this.files.forEach((file, path) => file.disposed && this.files.delete(path));\n    this.assets.forEach((file, path) => file.disposed && this.assets.delete(path));\n  }\n\n  compile(file) {\n    const path = file.path;\n    file.removed = false;\n    if (this.compiling.has(path)) {\n      this._resetTimer();\n      return;\n    }\n\n    this.compiling.add(path);\n    file.compile().finally(() => {\n      this.compiling.delete(path);\n      this._resetTimer();\n    }).then(() => {\n      debug(`Compiled ${path}`);\n      this.compiled.add(path);\n    });\n  }\n\n  compileDependencyParents(path) {\n    const isAsset = this.conventions.assets(path);\n    const files = isAsset ? this.assets : this.files;\n    const paths = [];\n    const parents = [];\n\n    files.forEach((depFile, depPath) => {\n      const deps = depFile.dependencies;\n      const isDep = anymatch(deps, path) && !this.compiled.has(depPath);\n      if (!isDep) return;\n      paths.push(depPath);\n      parents.push(depFile);\n    });\n\n    if (!parents.length) return;\n    debug(`Compiling ${isAsset ? 'asset' : 'dependency'} ${path} parent(s): ${paths.join(', ')}`);\n    parents.forEach(file => this.compile(file));\n  }\n\n  _addAsset(path) {\n    const file = new Asset(path, this.publicPath, this.conventions.assets);\n    this.assets.set(file.path, file);\n    return file;\n  }\n\n  _addFile(path) {\n    const file = new SourceFile(path, this.conventions.vendor, this.moduleWrapper, this);\n    this.files.set(file.path, file);\n    return file;\n  }\n\n  _change(path) {\n    if (this.disposed) return;\n    if (this.reading.has(path)) return;\n\n    debug(`Reading ${path}`);\n    const readDate = Date.now();\n    this.reading.set(path, readDate);\n\n    readAndCache(path).then(() => {\n      const cachedDate = this.reading.get(path);\n      if (this.disposed || !cachedDate || cachedDate > readDate) return;\n      this.reading.delete(path);\n\n      const isIgnored = this.conventions.ignored(path);\n      if (!isIgnored) {\n        const isAsset = this.conventions.assets(path);\n        const file = isAsset ?\n          this.assets.get(path) || this._addAsset(path) :\n          this.files.get(path) || this._addFile(path);\n\n        this.compile(file);\n      }\n\n      if (!this.initial) this.compileDependencyParents(path);\n      this._resetTimer();\n    }, error => {\n      if (!this.disposed) {\n        throw new BrunchError('READ_FAILED', {path, error});\n      }\n    });\n  }\n\n  _unlink(path) {\n    const isIgnored = this.conventions.ignored(path);\n    if (isIgnored) {\n      this.compileDependencyParents(path);\n    } else {\n      const isAsset = this.conventions.assets(path);\n      const file = isAsset ? this.assets.get(path) : this.files.get(path);\n      if (file && !file.disposed) file.removed = true;\n    }\n    this._resetTimer();\n  }\n\n  _resetTimer() {\n    if (this.timer) clearTimeout(this.timer);\n    this.timer = setTimeout(() => {\n      this.removeDisposedFiles();\n      if (this.hasPendingFiles) {\n        this._resetTimer();\n      } else {\n        this.emit('ready');\n        this.compiled.clear();\n      }\n    }, this.resetTime);\n  }\n\n  dispose() {\n    this.files.forEach(file => file.dispose());\n    this.files = new FrozenMap();\n    this.assets.forEach(file => file.dispose());\n    this.assets = new FrozenMap();\n\n    this.reading = new FrozenMap();\n    this.compiling = new FrozenSet();\n    this.compiled = new FrozenSet();\n\n    this.disposed = true;\n    this.removeAllListeners();\n    clearTimeout(this.timer);\n\n    // You're frozen when your heart's not open.\n    Object.freeze(this);\n  }\n}\n\nmodule.exports = FileList;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/asset.js":"'use strict';\nconst debug = require('debug')('brunch:asset');\nconst sysPath = require('universal-path');\nconst readFromCache = require('fcache').readFile;\nconst processAsset = require('./pipeline').processAsset;\nconst BrunchError = require('../utils/error');\nconst isIgnored = require('./is_ignored');\n\n// Returns all parent directories:\n// < parentDirs('app/assets/thing/index.html')\n// > ['app/', 'app/assets/', 'app/assets/thing/']\nconst parentDirs = path => {\n  return path.split('/').map((part, index, parts) => {\n    return parts.slice(0, index).concat(part, '').join('/');\n  }).slice(0, -1);\n};\n\nclass Asset {\n  constructor(path, publicPath, assetsConvention) {\n    debug(`Init asset ${path}`);\n\n    this.destinationPath = this.path = path;\n    this.compiled = '';\n    this.removed = this.disposed = false;\n\n    this._publicPath = publicPath;\n    this._assetsConvention = assetsConvention;\n    this._wasProcessed = false;\n    this._rawSource = new Buffer(0);\n\n    this.error = null;\n    this.dependencies = [];\n    this.compilationTime = 0;\n\n    // Disallow adding new properties and changing descriptors.\n    Object.seal(this);\n  }\n\n  get source() {\n    return `${this._rawSource}`;\n  }\n\n  get copyTime() {\n    return this.compilationTime;\n  }\n\n  compile() {\n    const path = this.path;\n    if (this.disposed) {\n      throw new BrunchError('ALREADY_DISPOSED', {path});\n    }\n\n    if (isIgnored(path)) return Promise.resolve(this);\n\n    return readFromCache(path)\n      .then(data => {\n        const asset = this;\n        asset._wasProcessed = false;\n        asset._rawSource = data;\n\n        return {\n          path,\n          get data() {\n            asset._wasProcessed = true;\n            return `${data}`;\n          },\n        };\n      })\n      .then(processAsset)\n      .then(file => this._updateCache(file))\n      .catch(error => {\n        this.error = error;\n        return this;\n      });\n  }\n\n  _updateCache(file) {\n    const path = sysPath.normalize(file.path);\n    const assetsDir = parentDirs(path).find(this._assetsConvention);\n    if (!assetsDir) {\n      throw new BrunchError('MOVED_ASSET', {path});\n    }\n\n    const rel = sysPath.relative(assetsDir, path);\n\n    this.error = null;\n    this.destinationPath = sysPath.join(this._publicPath, rel);\n    this.compiled = this._wasProcessed ? file.data : this._rawSource;\n    this.dependencies = file.dependencies || [];\n    this.compilationTime = Date.now();\n  }\n\n  dispose() {\n    debug(`Disposing asset ${this.path}`);\n\n    this.path = '';\n    this._rawSource = new Buffer(0);\n    this.compiled = '';\n    this.disposed = true;\n    this.error = null;\n    this.dependencies = Object.freeze([]);\n\n    // You're frozen when your heart's not open.\n    Object.freeze(this);\n  }\n}\n\nmodule.exports = Asset;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/pipeline.js":"'use strict';\nconst sysPath = require('universal-path');\nconst logger = require('loggy');\nconst debug = require('debug')('brunch:pipeline');\nconst deppack = require('deppack'); // isNpm\nconst parallel = require('../workers').parallel;\nconst BrunchError = require('../utils/error');\nconst pull = require('../utils/helpers').pull;\n\n// Pipeline: File -> File.\n// Takes file and a) lints b) compiles c) extracts dependencies from it.\n\nconst extRe = /(\\.\\w+)+$/;\nconst rethrow = message => error => {\n  if (!(error instanceof Error)) {\n    error = new Error(error);\n  }\n\n  error.pipelineCode = message;\n  throw error;\n};\n\nconst lint = file => {\n  const path = file.path;\n  const linters = respondTo('lint').filter(linter => {\n    return linter.pattern.test(path);\n  }).map(linter => {\n    debug(`Linting ${path} @ ${linter.brunchPluginName}`);\n    return linter.lint(file);\n  });\n\n  return Promise.all(linters).catch(error => {\n    if (/^warn:\\s/i.test(error)) {\n      logger.warn(`Linting of ${path}: ${error}`);\n    } else {\n      rethrow('Linting')(error);\n    }\n  }).then(() => file);\n};\n\nconst compileStatic = (file, compiler) => {\n  const path = file.path;\n  debug(`Compiling asset ${path} @ ${compiler.brunchPluginName}`);\n\n  return compiler.compileStatic(file).then(compiled => {\n    if (compiled == null) return file;\n    if (compiled.data == null) {\n      throw new BrunchError('FILE_DATA_INVALID', {path});\n    }\n\n    const deps = Array.isArray(compiled.dependencies) ?\n      Promise.resolve(compiled.dependencies) :\n      getDependencies(file, compiler);\n\n    return deps.then(dependencies => {\n      const path = compiled.path || file.path;\n\n      return Object.assign({}, compiled, {\n        dependencies,\n        path: compiler.staticTargetExtension ?\n          path.replace(extRe, compiler.staticTargetExtension) :\n          path,\n      });\n    });\n  }).catch(rethrow('Compiling asset'));\n};\n\n// Extract files' paths that depend on current file.\nconst getDependencies = (file, compiler) => {\n  if (typeof compiler.getDependencies !== 'function') {\n    return Promise.resolve();\n  }\n\n  debug(`Fetching dependencies ${file.path} @ ${compiler.brunchPluginName}`);\n  return compiler.getDependencies(file).then(deps => {\n    return deps.concat(deps.patterns || []).map(sysPath.normalize);\n  }).catch(rethrow('Dependency parsing'));\n};\n\nconst processAsset = parallel('PROCESS_ASSET', file => {\n  const compilers = respondTo('compileStatic').filter(compiler => {\n    return compiler.type === 'template';\n  });\n\n  const nextCompiler = file => {\n    const compiler = pull(compilers, compiler => {\n      return compiler.staticPattern.test(file.path);\n    });\n\n    return compiler ?\n      compileStatic(file, compiler).then(nextCompiler) :\n      file;\n  };\n\n  return nextCompiler(file);\n});\n\nconst compile = (file, compiler) => {\n  const path = file.path;\n  debug(`Compiling ${path} @ ${compiler.brunchPluginName}`);\n\n  return compiler.compile(file).then(compiled => {\n    if (compiled == null) return file;\n    if (compiled.data == null) {\n      throw new BrunchError('FILE_DATA_INVALID', {path});\n    }\n\n    const deps = Array.isArray(compiled.dependencies) ?\n      Promise.resolve(compiled.dependencies) :\n      getDependencies(file, compiler);\n\n    return deps.then(dependencies => {\n      const path = compiled.path || file.path;\n\n      return Object.assign({}, compiled, {\n        dependencies,\n        type: compiler.type,\n        path: compiler.targetExtension ?\n          path.replace(extRe, compiler.targetExtension) :\n          path,\n      });\n    });\n  }).catch(rethrow('Compiling'));\n};\n\nconst processFile = parallel('PROCESS_FILE', file => {\n  const path = file.path;\n  const isNpm = deppack.isNpm(path);\n\n  const usePlugin = isNpm ?\n    compiler => npmCompilers.includes(compiler.brunchPluginName) :\n    () => true;\n\n  const compilers = respondTo('compile').filter(usePlugin);\n  const nextCompiler = file => {\n    const compiler = pull(compilers, compiler => {\n      return compiler.pattern.test(file.path);\n    });\n\n    return compiler ?\n      compile(file, compiler).then(nextCompiler) :\n      file;\n  };\n\n  const compiled = lint(file).then(nextCompiler);\n  if (!isNpm) return compiled;\n\n  return compiled.then(file => {\n    const absPath = sysPath.resolve(path);\n\n    return deppack.wrapSourceInModule(file.data, absPath).then(wrapped => {\n      file.data = wrapped;\n      return file;\n    });\n  });\n});\n\nconst respondTo = key => plugins.filter(plugin => {\n  return typeof plugin[key] === 'function';\n});\n\nlet plugins = [];\nlet npmCompilers = [];\n\nmodule.exports = {\n  processAsset,\n  processFile,\n  setPlugins(array) {\n    plugins = array;\n  },\n  setNpmCompilers(array) {\n    npmCompilers = array;\n  },\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/fs_utils/source_file.js":"'use strict';\nconst debug = require('debug')('brunch:file');\nconst readFromCache = require('fcache').readFile;\nconst logger = require('loggy');\nconst deppack = require('deppack');\nconst processFile = require('./pipeline').processFile;\nconst SourceMapConsumer = require('source-map').SourceMapConsumer;\nconst SourceNode = require('source-map').SourceNode;\nconst BrunchError = require('../utils/error');\nconst helpers = require('../utils/plugins').helpers;\n\nconst identityNode = (code, path) => {\n  const lines = code.split('\\n').map((line, index) => {\n    return new SourceNode(index + 1, 0, path, `${line}\\n`);\n  });\n\n  return new SourceNode(1, 0, null, lines);\n};\n\nconst prepSourceMap = (code, sourceMap) => {\n  const consumer = new SourceMapConsumer(typeof sourceMap === 'string' ?\n    JSON.parse(sourceMap) : sourceMap\n  );\n\n  return SourceNode.fromStringWithSourceMap(code, consumer);\n};\n\nconst wrappedNode = (path, wrapped, sourceMap) => {\n  const data = wrapped.data;\n  const isIdentity = sourceMap == null;\n  const node = isIdentity ? identityNode(data, path) : prepSourceMap(data, sourceMap);\n\n  node.isIdentity = isIdentity;\n  node.source = path;\n  node.setSourceContent(path, data);\n  node.prepend(wrapped.prefix);\n  node.add(wrapped.suffix);\n\n  return node;\n};\n\nconst getInitialType = path => {\n  if (deppack.isNpmJSON(path) || path.endsWith('.js')) return 'javascript';\n  if (path.endsWith('.css')) return 'stylesheet';\n\n  return '';\n};\n\nclass SourceFile {\n  constructor(path, vendorConvention, moduleWrapper, fileList) {\n    debug(`Init file ${path}`);\n\n    this.isVendor = vendorConvention(path);\n    this._moduleWrapper = moduleWrapper;\n    this._exploreDeps = deppack.exploreDeps(fileList);\n\n    this._realPath = this.path = path;\n    this.source = '';\n    this.removed = this.disposed = false;\n\n    this.error = null;\n    this.dependencies = [];\n    this.compilationTime = 0;\n\n    // treat json files from node_modules as js\n    this.type = getInitialType(path);\n    this.targets = {};\n\n    // Disallow adding new properties and changing descriptors.\n    Object.seal(this);\n  }\n\n  get _shouldBeWrapped() {\n    return this.isJS && !this.isVendor;\n  }\n\n  get isHelper() {\n    return helpers.includes(this.path);\n  }\n\n  get isJS() {\n    return this.type === 'javascript' || this.type === 'template';\n  }\n\n  get isModule() {\n    return !(this.isHelper || this.isVendor);\n  }\n\n  compile() {\n    const path = this.path = this._realPath;\n    if (this.disposed) {\n      throw new BrunchError('ALREADY_DISPOSED', {path});\n    }\n\n    return readFromCache(path)\n      .then(data => {\n        data += '';\n        this.source = data;\n        return {path, data};\n      })\n      .then(processFile)\n      .then(file => {\n        this.type = this.type || file.type || '';\n        file.compiled = file.data;\n        return file;\n      })\n      .then(this._exploreDeps)\n      .then(file => {\n        file.data = file.compiled;\n        return file;\n      })\n      .then(file => this._updateCache(file))\n      .catch(error => {\n        this.error = error;\n        return this;\n      });\n  }\n\n  _updateCache(file) {\n    this.error = null;\n    this.compilationTime = Date.now();\n    this.dependencies = file.dependencies || [];\n\n    const data = file.data;\n\n    return this._updateMap(data, file.sourceMap).then(node => {\n      this.targets = {\n        [this.type]: {data, node},\n      };\n\n      const exports = file.exports;\n      if (!exports || this.type === 'javascript') return;\n\n      this.targets.javascript = {\n        data: exports,\n        node: wrappedNode(this.path, this._wrap(exports)),\n      };\n    });\n  }\n\n  _wrap(data) {\n    return this._moduleWrapper(this.path, data);\n  }\n\n  _checkAndWrap(data) {\n    if (this._shouldBeWrapped) return this._wrap(data);\n\n    return {\n      data,\n      prefix: '',\n      suffix: '',\n    };\n  }\n\n  _updateMap(compiled, sourceMap) {\n    const wrapped = this._checkAndWrap(compiled);\n    const path = this.path;\n    const node = wrappedNode(path, wrapped, sourceMap);\n\n    if (sourceMap) {\n      debug(`Generated source map for '${path}'`);\n    }\n\n    // the supplied source map might contain more than one source file\n    const addSource = path => readFromCache(path).then(content => {\n      node.setSourceContent(path, content);\n    }).catch(error => {\n      logger.error(`Source map generation failed for '${path}': `, error);\n    });\n\n    const sources = sourceMap && sourceMap.sources || [];\n    return Promise.all(sources.map(addSource)).then(() => node);\n  }\n\n  dispose() {\n    debug(`Disposing file ${this.path}`);\n\n    this.path = '';\n    this.source = '';\n    this.disposed = true;\n    this.error = null;\n\n    this.targets = Object.freeze({});\n    this.dependencies = Object.freeze([]);\n\n    // You're frozen when your heart's not open.\n    Object.freeze(this);\n  }\n}\n\nmodule.exports = SourceFile;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/plugins.js":"'use strict';\nconst debug = require('debug')('brunch:plugins');\nconst logger = require('loggy');\nconst profile = require('since-app-start').profile;\nconst flatten = require('./helpers').flatten;\nconst deepFreeze = require('./helpers').deepFreeze;\nconst BrunchError = require('./error');\nconst adapter = require('./plugin-adapter');\nconst sysPath = require('universal-path');\n\nconst loadPackage = pkgPath => {\n  profile('Loading plugins');\n  const clearCache = () => delete require.cache[pkgPath];\n\n  try {\n    clearCache();\n    const pkg = require(pkgPath);\n    if (!pkg.dependencies) pkg.dependencies = {};\n    if (!pkg.devDependencies) pkg.devDependencies = {};\n\n    return deepFreeze(pkg);\n  } catch (error) {\n    throw new BrunchError('CWD_INVALID', {error});\n  } finally {\n    clearCache();\n  }\n};\n\nconst uniqueDeps = pkg => {\n  const deps = pkg.dependencies;\n  const names = Object.keys(deps);\n\n  Object.keys(pkg.devDependencies).forEach(devDep => {\n    if (devDep in deps) {\n      logger.warn(`You have declared ${devDep} in package.json more than once`);\n    } else {\n      names.push(devDep);\n    }\n  });\n\n  return names;\n};\n\n/* Load brunch plugins, group them and initialise file watcher.\n *\n * configParams - Object. Optional. Params will be set as default config items.\n *\n */\n\nconst ignoredPlugins = [\n  'javascript-brunch',\n  'css-brunch',\n];\n\nconst plugins = (config, craDeps) => {\n  profile('Loaded config');\n\n  const absRoot = sysPath.resolve(config.paths.root);\n  const pkgPath = sysPath.join(absRoot, config.paths.packageConfig);\n  const npmPath = sysPath.join(absRoot, 'node_modules');\n\n  const pkg = config.cra ? {dependencies: craDeps} : loadPackage(pkgPath);\n\n  const on = config.plugins.on;\n  const off = config.plugins.off;\n  const only = config.plugins.only;\n\n  const deps = uniqueDeps(pkg).filter(name => {\n    if (!name.includes('brunch')) return false;\n    if (ignoredPlugins.includes(name)) return false;\n    if (off.includes(name)) return false;\n    if (only.length && !only.includes(name)) return false;\n    return true;\n  });\n\n  const plugins = deps.reduce((plugins, name) => {\n    try {\n      const Plugin = require(sysPath.join(npmPath, name));\n      if (Plugin && Plugin.prototype && Plugin.prototype.brunchPlugin) {\n        const plugin = new Plugin(config);\n        plugin.brunchPluginName = name;\n        plugins.push(adapter(plugin));\n      }\n    } catch (error) {\n      if (error.code === 'MODULE_NOT_FOUND' && name in pkg.dependencies) {\n        throw new BrunchError('RUN_NPM_INSTALL', {error});\n      }\n      logger.warn(`Loading of ${name} failed due to`, error);\n    }\n    return plugins;\n  }, [])\n  .filter(plugin => {\n    // Does the user's config say this plugin should definitely be used?\n    if (on.includes(plugin.brunchPluginName)) return true;\n\n    // If the plugin is an optimizer that doesn't specify a defaultEnv\n    // decide based on the config.optimize setting\n    const env = plugin.defaultEnv;\n    if (!env) {\n      return plugin.optimize ? config.optimize : true;\n    }\n\n    // Finally, is it meant for either any environment or\n    // an active environment?\n    return env === '*' || config.env.includes(env);\n  });\n\n  const respondTo = key => plugins.filter(plugin => {\n    return typeof plugin[key] === 'function';\n  });\n\n  const compilers = respondTo('compile');\n  const names = plugins.map(plugin => plugin.brunchPluginName).join(', ');\n  debug(`Loaded plugins: ${names}`);\n\n  if (config.hot) {\n    const hmrCompiler = compilers.find(compiler => {\n      return compiler.brunchPluginName === 'auto-reload-brunch';\n    });\n\n    if (!hmrCompiler) throw new BrunchError('HMR_PLUGIN_MISSING');\n    if (!hmrCompiler.supportsHMR) throw new BrunchError('HMR_PLUGIN_UNSUPPORTED');\n  }\n\n  /* Get paths to files that plugins include. E.g. handlebars-brunch includes\n   * `../vendor/handlebars-runtime.js` with path relative to plugin.\n   */\n  const getIncludes = () => {\n    const includes = plugins.map(plugin => {\n      return plugin.include.then(paths => {\n        return paths.map(path => {\n          if (!sysPath.isAbsolute(path)) {\n            path = sysPath.join(npmPath, plugin.brunchPluginName, path);\n          }\n\n          return sysPath.relative(absRoot, path);\n        });\n      });\n    });\n\n    return Promise.all(includes).then(flatten);\n  };\n\n  return getIncludes().then(includes => {\n    [].push.apply(helpers, includes);\n    profile('Loaded plugins');\n\n    return {\n      hooks: {\n        preCompile: respondTo('preCompile'),\n        onCompile: respondTo('onCompile'),\n        teardown: respondTo('teardown'),\n      },\n      plugins: {\n        includes,\n        compilers,\n        optimizers: respondTo('optimize'),\n        all: plugins,\n      },\n    };\n  });\n};\n\nconst helpers = plugins.helpers = [];\nmodule.exports = plugins;\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/plugin-adapter.js":"'use strict';\nconst microPromisify = require('micro-promisify');\nconst logger = require('loggy');\n\nconst normExt = ext => {\n  return typeof ext === 'string' ?\n    ext.replace(/^\\.*/, '.') :\n    ext;\n};\n\nconst extToRegExp = ext => {\n  if (!ext) return;\n  const escaped = normExt(ext).replace(/\\./g, '\\\\.');\n  return new RegExp(`${escaped}$`, 'i');\n};\n\n// Normalize includes to promise that resolves to array.\nconst normInclude = plugin => {\n  let include = plugin.include;\n  if (typeof include === 'function') {\n    include = include.call(plugin);\n  }\n\n  const value = Promise.resolve(include).then(path => {\n    return path == null ? [] : [].concat(path);\n  });\n\n  // Don't call setter (it is probably missing)\n  Object.defineProperty(plugin, 'include', {\n    value,\n    writable: true,\n    configurable: true,\n  });\n};\n\nconst normMethods = plugin => {\n  const methods = {};\n  methods.lint = methods.getDependencies = [bind, promisify(false), thenify, warnIfLong];\n  methods.compile = methods.optimize = [bind, promisify(true), thenify, wrapStrings, warnIfLong];\n  methods.compileStatic = [bind, thenify, wrapStrings, warnIfLong];\n\n  Object.keys(methods).forEach(key => {\n    const fn = plugin[key];\n    if (typeof fn !== 'function') return;\n\n    const decorators = methods[key];\n    const compose = (fn, decorator) => decorator(fn, plugin, key);\n    const value = decorators.reduce(compose, fn);\n\n    Object.defineProperty(plugin, key, {value});\n  });\n};\n\nconst bind = (fn, plugin) => fn.bind(plugin);\nconst promisify = returnsFile => fn => {\n  switch (fn.length) {\n    case 1:\n      // Modern API:\n      return fn;\n    case 2:\n      // Legacy API:\n      return returnsFile ?\n        microPromisify(fn) : // fn(file, callback) => void\n        file => fn(file.data, file.path); // fn(data, path) => Promise\n    case 3:\n      // Legacy API: fn(data, path, callback) => void\n      const promisified = microPromisify(fn);\n      return file => promisified(file.data, file.path);\n  }\n};\n\nconst thenify = fn => {\n  return file => Promise.resolve(file).then(fn);\n};\n\nconst wrapStrings = fn => {\n  return file => fn(file).then(data => {\n    return typeof data === 'string' ? {data} : data;\n  });\n};\n\nconst warnIfLong = (fn, plugin, key) => {\n  const warningLogInterval = 15000;\n  const tooLongMessage = `${plugin.brunchPluginName} is taking too long to ${key}`;\n\n  return file => {\n    const id = setInterval(() => {\n      logger.warn(`${tooLongMessage} @ ${file.path}`);\n    }, warningLogInterval);\n\n    return fn(file).finally(() => {\n      clearInterval(id);\n    });\n  };\n};\n\nmodule.exports = plugin => {\n  // Backwards compatibility for legacy optimizers.\n  if (typeof plugin.minify === 'function' && !plugin.optimize) {\n    plugin.optimize = plugin.minify;\n  }\n\n  normInclude(plugin);\n  normMethods(plugin);\n\n  plugin.targetExtension = normExt(plugin.targetExtension);\n  plugin.pattern = plugin.pattern ||\n    extToRegExp(plugin.extension) ||\n    /.^/; // never matches\n\n  if (plugin.type === 'template' && plugin.compileStatic) {\n    plugin.staticTargetExtension = normExt(plugin.staticTargetExtension) || '.html';\n    plugin.staticPattern = plugin.staticPattern ||\n      extToRegExp(plugin.staticExtension) ||\n      plugin.pattern;\n  }\n\n  return plugin;\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/config.js":"'use strict';\nrequire('micro-es7-shim');\nrequire('coffee-script').register();\n\nconst checkDeps = require('check-dependencies');\nconst sysPath = require('universal-path');\nconst anymatch = require('anymatch');\nconst logger = require('loggy');\nconst readComponents = require('read-components');\nconst debug = require('debug')('brunch:config');\nconst helpers = require('./helpers');\nconst deppack = require('deppack'); // isNpm, loadInit\nconst wrappers = require('./modules');\nconst validateConfig = require('./config-validate');\nconst BrunchError = require('./error');\nconst install = require('deps-install');\nconst defaultConfigFilename = 'brunch-config';\n\nconst checkNpmModules = config => {\n  if (config.npm.enabled && config.modules.definition !== 'commonjs' && config.modules.wrapper !== 'commonjs') {\n    throw new BrunchError('NPM_NOT_COMMONJS', config.modules);\n  }\n  return config;\n};\n\nconst dontMerge = files => {\n  const values = Object.values(files);\n\n  // this fn will be called on every nested object that will be merged\n  return (target, source) => {\n    if (!values.includes(target)) return () => true;\n\n    // this fn will be called on every enumerable entry in source\n    return key => {\n      // if either joinTo or entryPoints is overriden but not both, reset the other, as they are supposed to go hand-in-hand\n      const otherKey = key === 'joinTo' ? 'entryPoints' : key === 'entryPoints' ? 'joinTo' : null;\n      if (otherKey && otherKey in target && !(otherKey in source)) {\n        delete target[otherKey];\n      }\n\n      return false;\n    };\n  };\n};\n\nconst applyOverrides = (config, env) => {\n  // Allow the environment to be set from environment variable.\n  config.env = env;\n  if ('BRUNCH_ENV' in process.env) {\n    env.unshift(process.env.BRUNCH_ENV);\n  } else if ('NODE_ENV' in process.env) {\n    env.unshift(process.env.NODE_ENV);\n  }\n\n  // Preserve default config before overriding.\n  if (env.length && 'overrides' in config) {\n    config.overrides._default = {};\n    Object.keys(config).forEach(prop => {\n      const isObject = toString.call(config[prop]) === '[object Object]';\n      if (prop === 'overrides' || !isObject) return;\n\n      const override = config.overrides._default[prop] = {};\n      helpers.deepAssign(override, config[prop]);\n    });\n  }\n  env.forEach(override => {\n    const plug = config.plugins;\n    const overrideProps = config.overrides && config.overrides[override] || {};\n    const specials = {on: 'off', off: 'on'};\n\n    // Special override handling for plugins.on|off arrays (gh-826).\n    Object.keys(specials).forEach(k => {\n      const v = specials[k];\n      if (plug && plug[v]) {\n        if (overrideProps.plugins == null) overrideProps.plugins = {};\n        const item = overrideProps.plugins[v] || [];\n        const cItem = config.plugins[v] || [];\n        overrideProps.plugins[v] = item.concat(cItem.filter(plugin => {\n          const list = overrideProps.plugins[k];\n          return list && !list.includes(plugin);\n        }));\n      }\n    });\n    helpers.deepAssign(config, overrideProps, dontMerge(config.files));\n  });\n  // ensure server's public path takes overrides into account\n  config.server.publicPath = config.paths.public;\n  return config;\n};\n\nconst normalizeJoinConfig = joinTo => {\n  const object = typeof joinTo === 'string' ?\n    {[joinTo]: () => true} :\n    joinTo || {};\n\n  return Object.keys(object).reduce((subCfg, path) => {\n    const checker = object[path];\n    subCfg[path] = anymatch(checker);\n    return subCfg;\n  }, {});\n};\n\nconst normalizePluginHelpers = (items, subCfg) => {\n  if (items) return [].concat(items);\n\n  const destFiles = Object.keys(subCfg);\n  const joinMatch = destFiles.find(file => subCfg[file]('vendor/.'));\n  if (joinMatch) return [joinMatch];\n  const nameMatch = destFiles.find(file => /vendor/i.test(file));\n  if (nameMatch) return [nameMatch];\n  return [destFiles[0]];\n};\n\n/* Converts `config.files[...].joinTo` to one format.\n * config.files[type].joinTo can be a string, a map of {str: regexp} or a map\n * of {str: function}.\n * Also includes `config.files.javascripts.entryPoints`.\n *\n * Example output:\n *\n * {\n *   javascripts: {'*': {'javascripts/app.js': checker}, 'app/init.js': {'javascripts/bundle.js': 'app/init.js'}},\n *   templates: {'*': {'javascripts/app.js': checker2}}\n * }\n */\nconst createJoinConfig = (cfgFiles, paths) => {\n  if (cfgFiles.javascripts && 'joinTo' in cfgFiles.javascripts) {\n    if (!cfgFiles.templates) cfgFiles.templates = {};\n    if (!('joinTo' in cfgFiles.templates)) {\n      cfgFiles.templates.joinTo = cfgFiles.javascripts.joinTo;\n    }\n  }\n\n  const types = Object.keys(cfgFiles);\n  const joinConfig = types.reduce((joinConfig, type) => {\n    const fileCfg = cfgFiles[type];\n    const subCfg = normalizeJoinConfig(fileCfg.joinTo);\n    joinConfig[type] = subCfg;\n\n    // special matching for plugin helpers\n    const helpers = fileCfg.pluginHelpers;\n    subCfg.pluginHelpers = normalizePluginHelpers(helpers, subCfg);\n    return joinConfig;\n  }, {});\n\n  // the joinTo is just a special case of entryPoints\n  const entryPoints = types.reduce((entryPoints, type) => {\n    const point = entryPoints[type] = {};\n    if (type in joinConfig) point['*'] = joinConfig[type];\n    return entryPoints;\n  }, {});\n\n  const outPaths = [];\n  types.forEach(type => {\n    const fileCfg = cfgFiles[type];\n    if (!fileCfg.entryPoints) return;\n    if (type !== 'javascripts') {\n      logger.warn(`entryPoints can only be used with 'javascripts', not '${type}'`);\n      return;\n    }\n\n    Object.keys(fileCfg.entryPoints).forEach(target => {\n      const isTargetWatched = paths.watched.some(path => target.startsWith(`${path}/`));\n      if (!isTargetWatched) {\n        logger.warn(`The correct use of entry points is: \\`'entryFile.js': 'outputFile.js'\\`. You are trying to use '${target}' as an entry point, but it is probably an output file.`);\n      }\n      const entryCfg = fileCfg.entryPoints[target];\n      const alreadyDefined = Object.keys(entryCfg).some(out => out in joinConfig[type]);\n      if (alreadyDefined) {\n        logger.warn(`config.files.${type}.joinTo is already defined for '${target}', can't add an entry point`);\n        return;\n      }\n\n      const normalizedEntryCfg = normalizeJoinConfig(entryCfg);\n      Object.keys(normalizedEntryCfg).forEach(path => {\n        if (outPaths.includes(path)) {\n          logger.warn(`'${path}' is already used by another entry point, can't add it to config.files.${type}.entryPoints for '${target}'`);\n          delete normalizedEntryCfg[path];\n          return;\n        }\n\n        outPaths.push(path);\n      });\n      entryPoints[type][target] = normalizedEntryCfg;\n    });\n  });\n\n  return Object.freeze(entryPoints);\n};\n\nconst setLoggyOptions = config => {\n  if (config === false) {\n    logger.notifications = false;\n    return;\n  }\n\n  if (config === true) {\n    logger.warn('`config.notifications: true` is deprecated. Notifications are on by default. Remove the option');\n    config = {};\n  } else if (Array.isArray(config)) {\n    logger.warn('`config.notifications` array is deprecated. Use `config.notifications.levels` instead.');\n    config = {levels: config};\n  }\n\n  Object.assign(logger.notifications, {\n    app: 'Brunch',\n    icon: sysPath.resolve(__dirname, '..', 'logo.png'),\n  }, config);\n};\n\nconst setConfigDefaults = (config, configPath) => {\n  setLoggyOptions(config.notifications);\n\n  const join = (parent, name) => {\n    return sysPath.isAbsolute(name) ? name : sysPath.join(config.paths[parent], name);\n  };\n  const joinRoot = name => join('root', name);\n\n  // Paths.\n  const paths = config.paths;\n\n  paths.public = joinRoot(paths.public);\n  paths.watched = paths.watched.map(joinRoot);\n\n  if (paths.config == null) paths.config = configPath || joinRoot('config');\n  paths.packageConfig = joinRoot(paths.packageConfig);\n  paths.bowerConfig = joinRoot(paths.bowerConfig);\n\n  // Conventions.\n  const conventions = config.conventions;\n  if (paths.ignored) {\n    conventions.ignored = paths.ignored;\n  }\n\n  // Server.\n  const server = config.server;\n  server.publicPath = paths.public;\n  if (server.run == null) server.run = false;\n  if (!config.persistent) server.run = false;\n\n  // Hooks.\n  if (config.onCompile) {\n    config.hooks.onCompile = config.onCompile;\n  }\n  if (config.preCompile) {\n    config.hooks.preCompile = config.preCompile;\n  }\n\n  return config;\n};\n\nconst normalizeConfig = config => {\n  const paths = config.paths;\n  const modules = config.modules;\n  const watcher = config.watcher;\n\n  const maybeConfigs = Object.keys(require.extensions).map(ext => paths.config + ext);\n  const allConfigFiles = [paths.packageConfig, paths.bowerConfig].concat(maybeConfigs);\n  const conventions = {};\n\n  Object.keys(config.conventions).forEach(key => {\n    const include = key === 'ignored' ? allConfigFiles : [];\n    const checker = include.concat(config.conventions[key]);\n    const fn = anymatch(checker);\n\n    conventions[key] = key === 'vendor' ? fn :\n      path => !deppack.isNpm(path) && fn(path);\n  });\n\n  config._normalized = {\n    join: createJoinConfig(config.files, paths),\n    paths: Object.assign({allConfigFiles}, paths),\n    conventions,\n    packageInfo: {},\n    persistent: config.persistent,\n    isProduction: !!config.isProduction,\n    watcher: {\n      usePolling: watcher.usePolling,\n      awaitWriteFinish: watcher.awaitWriteFinish === true ?\n        {stabilityThreshold: 50, pollInterval: 10} :\n        watcher.awaitWriteFinish,\n    },\n    modules: {\n      wrapper: wrappers.normalizeWrapper(modules.wrapper, modules.nameCleaner),\n      definition: wrappers.normalizeDefinition(modules.definition),\n      autoRequire: modules.autoRequire,\n    },\n  };\n\n  return config;\n};\n\nconst trimTrailingSlashes = config => {\n  const paths = config.paths;\n  const trim = path => path.replace(/\\/$/, '');\n\n  paths.public = trim(paths.public);\n  paths.watched = paths.watched.map(trim);\n\n  return config;\n};\n\nconst addDefaultServer = config => {\n  if (config.server.path) return config;\n  try {\n    const defaultServerFilename = 'brunch-server';\n    const resolved = require.resolve(sysPath.resolve(defaultServerFilename));\n    try {\n      require(resolved);\n    } catch (error) {\n      // Do nothing.\n    }\n    if (config.server.path == null) {\n      config.server.path = resolved;\n    }\n  } catch (error) {\n    // Do nothing.\n  }\n  return config;\n};\n\nconst loadBower = config => {\n  // Since readComponents call its callback with many arguments, we hate to wrap it manually\n  const rootPath = config.paths.root;\n  const readBower = () => new Promise((resolve, reject) => {\n    if (!config.bower.enabled) return resolve([]);\n    readComponents(rootPath, 'bower', (err, components) => {\n      if (err) reject(err);\n      else resolve(components || []);\n    });\n  });\n\n  return readBower().then(components => {\n    const order = components\n      .sort((a, b) => {\n        if (a.sortingLevel === b.sortingLevel) {\n          return a.files[0] < b.files[0] ? -1 : 1;\n        }\n        return b.sortingLevel - a.sortingLevel;\n      })\n      .reduce((files, component) => {\n        return files.concat(component.files);\n      }, []);\n\n    return {components, order};\n  }, error => {\n    switch (error.code) {\n      case 'NO_BOWER_JSON':\n        logger.error('You probably need to execute `bower install` here.', error);\n        return install({rootPath, pkgType: 'bower'}).then(readBower);\n      case 'ENOENT':\n        logger.error(error);\n        break;\n    }\n\n    return {components: [], order: []}; // Default values\n  });\n};\n\nconst loadNpm = config => new Promise(resolve => {\n  const paths = config.paths;\n  const rootPath = sysPath.resolve(paths.root);\n  const jsonPath = sysPath.resolve(rootPath, paths.packageConfig);\n  const json = require(jsonPath);\n  resolve(deppack.loadInit(config, json));\n}).catch(error => {\n  if (error.code === 'MODULE_NOT_FOUND') {\n    throw new BrunchError('PKG_JSON_MISSING');\n  } else if (error instanceof SyntaxError) {\n    throw new BrunchError('PKG_JSON_INVALID', {error});\n  }\n  throw error;\n});\n\nconst checkComponents = config => {\n  const path = sysPath.resolve(config.paths.root, 'component.json');\n  helpers.fsExists(path).then(exists => {\n    if (exists) {\n      logger.warn('Detected component.json in project root. Component.json is no longer supported. You could switch to keeping dependencies in NPM (package.json), or revert to Brunch 2.2.');\n    }\n  });\n};\n\nconst addPackageManagers = config => {\n  checkComponents(config);\n  return Promise.all([\n    loadNpm(config),\n    loadBower(config),\n  ]).then(components => {\n    const norm = config._normalized.packageInfo;\n    norm.npm = components[0];\n    norm.bower = components[1];\n    return config;\n  });\n};\n\nconst minimalConfig = `\nmodule.exports = {\n  files: {\n    javascripts: {\n      joinTo: 'app.js'\n    }\n  }\n};`;\n\nconst tryToLoad = (configPath, fallbackHandler) => {\n  let fullPath;\n  let basename = configPath;\n\n  return new Promise(resolve => {\n    debug(`Trying to load ${configPath}`);\n    // Assign fullPath in two steps in case require.resolve throws.\n    fullPath = sysPath.resolve(configPath);\n    fullPath = require.resolve(fullPath);\n    delete require.cache[fullPath];\n    const resolved = require(fullPath);\n    basename = sysPath.basename(fullPath);\n    resolve(resolved);\n  }).then(obj => {\n    const config = obj && obj.config || obj;\n    if (config !== Object(config)) {\n      throw new BrunchError('CFG_NOT_OBJECT', {basename});\n    }\n    if (!config.files) {\n      throw new BrunchError('CFG_NO_FILES', {basename, minimalConfig});\n    }\n    return config;\n  }).catch(error => {\n    if (error.code !== 'MODULE_NOT_FOUND') {\n      throw new BrunchError('CFG_LOAD_FAILED', {error});\n    }\n\n    const path = /^Cannot find module '(.+)'/.exec(error.message)[1];\n    if (path.includes(fullPath)) {\n      if (!fallbackHandler) {\n        fallbackHandler = () => {\n          logger.error(`The directory does not seem to be a Brunch project. Create ${basename}.js or run brunch from the correct directory. ${error.toString().replace('Error: ', '')}`);\n          logger.error(`Here's a minimal brunch-config.js to get you started:\\n${minimalConfig}`);\n          process.exit(1);\n        };\n      }\n\n      if (configPath === defaultConfigFilename) {\n        return tryToLoad('config', fallbackHandler);\n      }\n\n      fallbackHandler();\n    } else if (!path.startsWith('.')) {\n      try {\n        const pkg = require(sysPath.resolve('.', 'package.json'));\n        if (pkg) {\n          const topLevelMod = path.split('/', 1)[0];\n          const deps = Object.assign({}, pkg.dependencies, pkg.devDependencies);\n          if (topLevelMod in deps) {\n            logger.warn(`Config requires '${topLevelMod}' which is in package.json but wasn't yet installed. Trying to install...`);\n            return install({pkgType: 'package'}).then(() => tryToLoad(configPath));\n          }\n        }\n      } catch (e) {\n        // error\n      }\n    }\n\n    throw error;\n  });\n};\n\nconst checkProjectDependencies = config => {\n  const packageDir = config.paths.root;\n  const scopeList = config._normalized.isProduction ?\n    ['dependencies'] :\n    ['dependencies', 'devDependencies'];\n\n  return checkDeps({packageDir, scopeList}).then(out => {\n    if (out.depsWereOk) return;\n    const pkgs = out.error.filter(x => x.includes(':')).map(x => x.split(':', 1)[0]);\n    throw pkgs;\n  }).catch(pkgs => {\n    // filter out symlinked packages\n    const pkgPath = pkg => sysPath.join(packageDir, 'node_modules', pkg);\n    const isNotSymlink = pkg => helpers.isSymlink(pkgPath(pkg)).then(x => !x);\n    return helpers.asyncFilter(pkgs, isNotSymlink).then(unmetPkgs => {\n      if (!unmetPkgs.length) return;\n      logger.info(`Using outdated versions of ${unmetPkgs.join(', ')}, trying to update to match package.json versions`);\n      return install({rootPath: packageDir, pkgType: 'package'});\n    });\n  }).then(() => config);\n};\n\nconst dontFreeze = ['static', 'overrides'];\n\nconst loadConfig = (persistent, options, fromWorker) => {\n  const configPath = options.config || defaultConfigFilename;\n  const params = initParams(persistent, options);\n\n  return tryToLoad(configPath)\n    .then(validateConfig)\n    .then(checkNpmModules)\n    .then(config => setConfigDefaults(config, configPath))\n    .then(fromWorker || addDefaultServer)\n    .then(config => applyOverrides(config, params.env))\n    .then(config => helpers.deepAssign(config, params))\n    .then(trimTrailingSlashes)\n    .then(normalizeConfig)\n    .then(checkProjectDependencies)\n    .then(fromWorker || addPackageManagers)\n    .then(helpers.deepFreeze(dontFreeze));\n};\n\n// worker don't need default server, deprecation warnings, or package manager support\nconst loadConfigWorker = (persistent, options) => {\n  return loadConfig(persistent, options, true);\n};\n\n/* Generate params that will be used as default config values.\n *\n * persistent - Boolean. Determines if brunch should run a web server.\n * options    - Object. {optimize, publicPath, server, port}.\n *\n * Returns Object.\n */\n\nconst initParams = (persistent, options) => {\n  const env = options.env;\n  const params = {\n    persistent,\n    stdin: options.stdin != null,\n    env: env ? env.split(',') : [],\n  };\n  if (options.production == null && process.env.NODE_ENV !== 'production') {\n    process.env.NODE_ENV = process.env.NODE_ENV || 'development';\n  } else {\n    process.env.NODE_ENV = 'production';\n    params.isProduction = true;\n    params.env.unshift('production');\n  }\n  if (options.publicPath) {\n    params.paths = {\n      public: options.publicPath,\n    };\n  }\n  if (persistent) {\n    const server = params.server = {};\n    if (options.server) server.run = true;\n    if (options.network) server.hostname = '0.0.0.0';\n    if (options.port) server.port = options.port;\n  }\n  return params;\n};\n\nmodule.exports = {\n  setConfigDefaults,\n  loadConfig,\n  loadConfigWorker,\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/modules.js":"'use strict';\nconst sysPath = require('universal-path');\nconst commonRequireDefinition = require('commonjs-require-definition');\n\nconst getWrapperFn = wrapper => {\n  switch (wrapper) {\n    case 'commonjs':\n      return name => ({\n        prefix: `require.register(\"${name}\", function(exports, require, module) {\\n`,\n        suffix: '});\\n\\n',\n      });\n\n    case 'amd':\n      return (name, data) => ({\n        data: data.replace(/define\\s*\\(/, `$&\"${name}\", `),\n      });\n\n    case false:\n      return (name, data) => data;\n  }\n\n  return wrapper;\n};\n\nconst normalizeResult = wrapper => (name, data) => {\n  const wrapped = wrapper(name, data);\n  if (typeof wrapped === 'string') {\n    const srcIndex = wrapped.indexOf(data);\n\n    return {\n      prefix: wrapped.slice(0, srcIndex),\n      data: srcIndex > 0 ? data : wrapped,\n      suffix: wrapped.slice(srcIndex + data.length),\n    };\n  }\n\n  return {\n    prefix: wrapped.prefix || '',\n    data: wrapped.data || data,\n    suffix: wrapped.suffix || '',\n  };\n};\n\nexports.normalizeWrapper = (wrapper, nameCleaner) => {\n  const wrapperFn = normalizeResult(getWrapperFn(wrapper));\n\n  return (path, compiled) => {\n    const name = sysPath.normalize(path).replace(/^(\\.\\.\\/)+/, '');\n    return wrapperFn(nameCleaner(name), compiled);\n  };\n};\n\nexports.normalizeDefinition = definition => {\n  switch (definition) {\n    case 'commonjs':\n      return () => commonRequireDefinition;\n    case 'amd':\n    case false:\n      return () => '';\n  }\n\n  return definition;\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/utils/config-validate.js":"'use strict';\nconst skemata = require('skemata');\nconst logger = require('loggy');\nconst BrunchError = require('./error');\n\nconst v = skemata.v;\nconst configBaseSchema = v.object({\n  paths: v.object({\n    root: v.string.default('.'),\n    public: v.string.default('public'),\n    watched: v.array(v.string).default(['app', 'test', 'vendor']),\n    ignored: v.deprecated(v.noop, 'moved to `config.conventions.ignored`'),\n    assets: v.deprecated(v.noop, 'moved to `config.conventions.assets`'),\n    test: v.deprecated(v.noop, 'moved to `config.conventions.test`'),\n    vendor: v.deprecated(v.noop, 'moved to `config.conventions.vendor`'),\n    config: v.string,\n    packageConfig: v.string.default('package.json'),\n    bowerConfig: v.string.default('bower.json'),\n  }).default({}),\n\n  rootPath: v.deprecated(v.noop, 'moved to `config.paths.root`'),\n  buildPath: v.deprecated(v.noop, 'moved to `config.paths.public`'),\n\n  files: v.objects({\n    keys: ['javascripts', 'templates', 'stylesheets'],\n    warner(key) {\n      if (['app', 'test', 'vendor', 'assets'].includes(key)) {\n        return 'was removed, use `config.paths.watched` instead';\n      }\n    },\n  }, v.object({\n    joinTo: v.either(\n      v.string,\n      v.objects({}, v.anymatch)\n    ),\n    entryPoints: v.objects({}, v.either(\n      v.string,\n      v.objects({}, v.anymatch)\n    )),\n    order: v.object({\n      before: v.anymatch,\n      after: v.anymatch,\n    }),\n    pluginHelpers: v.either(v.string, v.array(v.string)),\n    defaultPaths: v.deprecated(v.noop, 'was removed'),\n    defaultExtensions: v.deprecated(v.noop, 'was removed'),\n  })),\n\n  npm: v.object({\n    enabled: v.bool.default(true),\n    globals: v.objects({}, v.string),\n    aliases: v.objects({}, v.string),\n    styles: v.objects({}, v.array(v.string)),\n    static: v.array(v.string).default([]),\n    compilers: v.array(v.string).default([]),\n    detectProcess: v.bool.default(true),\n  }).default({}),\n\n  bower: v.object({\n    enabled: v.bool.default(true),\n  }).default({}),\n\n  cra: v.bool.default(false),\n\n  plugins: v.object({\n    on: v.array(v.string).default([]),\n    off: v.array(v.string).default([]),\n    only: v.array(v.string).default([]),\n    npm: v.deprecated(v.array(v.string).default([]), 'use `config.npm.compilers` instead'),\n  }, false).default({}),\n\n  conventions: v.object({\n    ignored: v.anymatch.default([/\\/_/, /vendor\\/(node|j?ruby-.+|bundle)\\//]),\n    assets: v.anymatch.default(/assets\\//),\n    vendor: v.anymatch.default(/(^bower_components|node_modules|vendor)\\//),\n  }).default({}),\n\n  modules: v.object({\n    wrapper: v.either(v.enum('commonjs', 'amd', false), v.function).default('commonjs'),\n    definition: v.either(v.enum('commonjs', 'amd', false), v.function).default('commonjs'),\n    autoRequire: v.objects({}, v.array(v.string)).default({}),\n    nameCleaner: v.function.default(path => path.replace(/^app\\//, '')),\n  }).default({}),\n\n  notificationsTitle: v.deprecated(v.string, 'use `config.notifications.app` instead'),\n  notifications: v.either(\n    v.bool,\n    v.array(v.string),\n    v.object({\n      app: v.string,\n      icon: v.string,\n      levels: v.array(v.string),\n      notify: v.function,\n    })\n  ),\n\n  optimize: v.bool.default(false),\n  sourceMaps: v.either(v.bool, v.enum('old', 'absoluteUrl', 'inline')).default(true),\n\n  server: v.object({\n    base: v.string.default(''),\n    port: v.int.default(3333),\n    run: v.bool.default(false),\n    hostname: v.string.default('localhost'),\n    indexPath: v.string.default('index.html'),\n    startupLogging: v.bool.default(true),\n    noPushState: v.bool.default(false),\n    noCors: v.bool.default(false),\n    stripSlashes: v.bool.default(false),\n    path: v.string,\n    command: v.string,\n    config: v.object({}).default({}),\n  }).default({}),\n\n  fileListInterval: v.int.default(65),\n\n  watcher: v.object({\n    usePolling: v.bool.default(false),\n    awaitWriteFinish: v.either(v.bool, v.object({})),\n  }).default({}),\n\n  hooks: v.object({\n    preCompile: v.function.default(v.noop),\n    onCompile: v.function.default(v.noop),\n    teardown: v.function.default(v.noop),\n  }).default({}),\n\n  hot: v.bool.default(false),\n\n  preCompile: v.deprecated(v.function, 'use `config.hooks.preCompile` instead'),\n  onCompile: v.deprecated(v.function, 'use `config.hooks.onCompile` instead'),\n});\n\nconst overrideSchema = v.merge(\n  configBaseSchema,\n  v.object({}),\n  {ignoreFirstDefaults: true}\n);\n\nconst productionOverrideSchema = v.merge(\n  configBaseSchema,\n  v.object({\n    optimize: v.bool.default(true),\n    sourceMaps: v.either(v.bool, v.enum('old', 'absoluteUrl', 'inline')).default(false),\n    overrides: v.deprecated(v.noop, 'can not define `overrides` inside an override'),\n\n    plugins: v.object({\n      autoReload: v.object({\n        enabled: v.bool.default(false),\n      }).default({}),\n    }).default({}),\n  }),\n  {ignoreFirstDefaults: true}\n).default({});\n\nconst configSchema = v.merge(\n  configBaseSchema,\n  v.object({\n    overrides: v.objects(\n      {specifics: {production: productionOverrideSchema}},\n      overrideSchema\n    ).default({}),\n  })\n);\n\nmodule.exports = config => {\n  const schema = configSchema(config);\n  const formatted = skemata.formatObject(schema, 'config');\n  formatted.errors.forEach(error => {\n    logger.error(`${error.path}: ${error.result}`);\n  });\n  formatted.warnings.forEach(warn => {\n    logger.warn(`${warn.path}: ${warn.warning}`);\n  });\n  if (!schema.ok) {\n    throw new BrunchError('CFG_INVALID');\n  }\n  return config;\n};\n","/home/travis/build/npmtest/node-npmtest-brunch/node_modules/brunch/lib/workers/job-processor.js":"'use strict';\nrequire('micro-es7-shim');\nrequire('promise.prototype.finally').shim();\nconst loadConfigWorker = require('../utils/config').loadConfigWorker;\nconst initPlugins = require('../utils/plugins');\n\nlet cfg, plugins; // eslint-disable-line prefer-const\n\nconst options = JSON.parse(process.env.BRUNCH_OPTIONS);\nloadConfigWorker(false, options).then(_cfg => {\n  cfg = _cfg;\n  return initPlugins(cfg).then(_plugins => {\n    plugins = _plugins.plugins;\n    process.send('ready');\n  });\n});\n\nconst jobs = require('./jobs');\n\nprocess.on('message', msg => {\n  const type = msg.type;\n  const data = msg.data;\n\n  const job = jobs[type];\n  if (!job) console.error('INVALID_JOB_TYPE', type);\n  const hash = job.deserialize({plugins}, data.hash);\n  job.work(hash).then(result => {\n    process.send({result});\n  }, error => {\n    const err = typeof error === 'string' ? new Error(error) : error;\n    const data = {error: err.message, stack: err.stack};\n    process.send(data);\n  });\n});\n"}